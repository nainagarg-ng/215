{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import glob\n",
    "import io  # for BytesIO\n",
    "import itertools\n",
    "# Imports Python standard library logging\n",
    "import logging\n",
    "import os\n",
    "import tarfile\n",
    "import time\n",
    "import zipfile\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "# W&B\n",
    "import wandb\n",
    "# import fastparquet\n",
    "from google.cloud import storage\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.layers import Input, LSTM, Dropout, Embedding, Dense, Conv1D, MaxPooling1D\n",
    "from tensorflow.keras.models import Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 29882799 entries, 0 to 30998015\n",
      "Data columns (total 5 columns):\n",
      " #   Column   Dtype  \n",
      "---  ------   -----  \n",
      " 0   domains  object \n",
      " 1   isdga    int64  \n",
      " 2   actor    object \n",
      " 3   length   int64  \n",
      " 4   entropy  float64\n",
      "dtypes: float64(1), int64(2), object(2)\n",
      "memory usage: 1.3+ GB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('/Users/daniel/Synology_Ongoing/HES_Data_Science/AC215/DGAs.csv', index_col=0)\n",
    "df.drop_duplicates(subset='domains', inplace=True)\n",
    "df.dropna(inplace=True)\n",
    "df.info(memory_usage=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def create_lstm_dataset(data_frame, sequence_length=10, batch_size=32, validation_split=0.2):\n",
    "    \"\"\"\n",
    "    Create a TensorFlow Dataset for LSTM classification.\n",
    "\n",
    "    Parameters:\n",
    "    - data_frame: Pandas DataFrame containing 'domains' and 'classes.'\n",
    "    - sequence_length: Length of input sequences for LSTM.\n",
    "    - batch_size: Batch size for training.\n",
    "    - validation_split: Fraction of the data to be used for validation.\n",
    "\n",
    "    Returns:\n",
    "    - train_dataset: TensorFlow Dataset for training.\n",
    "    - val_dataset: TensorFlow Dataset for validation.\n",
    "    - num_classes: Number of unique classes in the dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert domains and classes to numerical values\n",
    "    data_frame['classes'] = data_frame['actor']\n",
    "    unique_classes = data_frame['classes'].unique()\n",
    "    class_to_index = {cls: idx for idx, cls in enumerate(unique_classes)}\n",
    "    data_frame['class_index'] = data_frame['classes'].map(class_to_index)\n",
    "\n",
    "    # Convert each character in the 'domains' column to numeric representation\n",
    "    char_to_index = {char: idx + 1 for idx, char in enumerate(set(''.join(data_frame['domains'])))}\n",
    "    data_frame['domain_indices'] = data_frame['domains'].apply(lambda x: np.array([char_to_index[char] for char in x]))\n",
    "\n",
    "    # Split the dataset into training and validation sets\n",
    "    train_data, val_data = train_test_split(data_frame, test_size=validation_split) #, stratify=data_frame['class_index'])\n",
    "\n",
    "    # # Create sequences of input data and corresponding labels\n",
    "    # def create_sequences(df):\n",
    "    #     sequences = []\n",
    "    #     labels = []\n",
    "\n",
    "    #     for i in range(len(df) - sequence_length):\n",
    "    #         seq = df['domain_indices'].values[i:i + sequence_length]\n",
    "    #         label = df['class_index'].values[i + sequence_length]\n",
    "    #         sequences.append(seq)\n",
    "    #         labels.append(label)\n",
    "\n",
    "    #     return sequences, labels\n",
    "\n",
    "    # train_sequences, train_labels = create_sequences(train_data)\n",
    "    # val_sequences, val_labels = create_sequences(val_data)\n",
    "\n",
    "    train_sequences = np.array(train_data['domain_indices'])\n",
    "    train_labels = np.array(train_data['class_index'])\n",
    "    val_sequences = np.array(val_data['domain_indices'])\n",
    "    val_labels = np.array(val_data['class_index'])\n",
    "\n",
    "\n",
    "\n",
    "    # Convert sequences and labels to TensorFlow Dataset\n",
    "    print(train_sequences)\n",
    "    print(train_labels)\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((train_sequences, train_labels))\n",
    "    val_dataset = tf.data.Dataset.from_tensor_slices((val_sequences, val_labels))\n",
    "\n",
    "    # Batch and shuffle the datasets\n",
    "    train_dataset = train_dataset.shuffle(buffer_size=len(train_sequences)).batch(batch_size)\n",
    "    val_dataset = val_dataset.batch(batch_size)\n",
    "\n",
    "    # Get the number of unique classes\n",
    "    num_classes = len(unique_classes)\n",
    "\n",
    "    return train_dataset, val_dataset, num_classes\n",
    "\n",
    "# Example usage:\n",
    "# Assuming you have a DataFrame df with columns 'domains' and 'classes'\n",
    "# train_dataset, val_dataset, num_classes = create_lstm_dataset(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "  # Convert domains and classes to numerical values\n",
    "data_frame =  df_small.copy()\n",
    "data_frame['classes'] = data_frame['actor']\n",
    "unique_classes = data_frame['classes'].unique()\n",
    "class_to_index = {cls: idx for idx, cls in enumerate(unique_classes)}\n",
    "data_frame['class_index'] = data_frame['classes'].map(class_to_index)\n",
    "\n",
    "# Convert each character in the 'domains' column to numeric representation\n",
    "char_to_index = {char: idx + 1 for idx, char in enumerate(set(''.join(data_frame['domains'])))}\n",
    "data_frame['domain_indices'] = data_frame['domains'].apply(lambda x: [char_to_index[char] for char in x])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domains</th>\n",
       "      <th>isdga</th>\n",
       "      <th>actor</th>\n",
       "      <th>length</th>\n",
       "      <th>entropy</th>\n",
       "      <th>classes</th>\n",
       "      <th>class_index</th>\n",
       "      <th>domain_indices</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zba93jwfmthdo.com</td>\n",
       "      <td>1</td>\n",
       "      <td>legit</td>\n",
       "      <td>17</td>\n",
       "      <td>3.852169</td>\n",
       "      <td>legit</td>\n",
       "      <td>0</td>\n",
       "      <td>[31, 20, 36, 14, 35, 8, 27, 13, 22, 21, 11, 7,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>thchsnus.xyz</td>\n",
       "      <td>1</td>\n",
       "      <td>legit</td>\n",
       "      <td>12</td>\n",
       "      <td>3.251629</td>\n",
       "      <td>legit</td>\n",
       "      <td>0</td>\n",
       "      <td>[21, 11, 30, 11, 1, 25, 5, 1, 19, 6, 17, 31]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>viewedhands.com</td>\n",
       "      <td>1</td>\n",
       "      <td>legit</td>\n",
       "      <td>15</td>\n",
       "      <td>3.640224</td>\n",
       "      <td>legit</td>\n",
       "      <td>0</td>\n",
       "      <td>[15, 33, 2, 27, 2, 7, 11, 36, 25, 7, 1, 19, 30...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4hmjw5q7w9qr.net</td>\n",
       "      <td>1</td>\n",
       "      <td>legit</td>\n",
       "      <td>16</td>\n",
       "      <td>3.750000</td>\n",
       "      <td>legit</td>\n",
       "      <td>0</td>\n",
       "      <td>[29, 11, 22, 8, 27, 12, 37, 16, 27, 14, 37, 3,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>norduserforum.com</td>\n",
       "      <td>1</td>\n",
       "      <td>legit</td>\n",
       "      <td>17</td>\n",
       "      <td>3.292770</td>\n",
       "      <td>legit</td>\n",
       "      <td>0</td>\n",
       "      <td>[25, 32, 3, 7, 5, 1, 2, 3, 13, 32, 3, 5, 22, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>khhvovnvm.dyndns.org</td>\n",
       "      <td>1</td>\n",
       "      <td>legit</td>\n",
       "      <td>20</td>\n",
       "      <td>3.446439</td>\n",
       "      <td>legit</td>\n",
       "      <td>0</td>\n",
       "      <td>[9, 11, 11, 15, 32, 15, 25, 15, 22, 19, 7, 17,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>deoyuwxfbxxtteobqgg.com</td>\n",
       "      <td>1</td>\n",
       "      <td>legit</td>\n",
       "      <td>23</td>\n",
       "      <td>3.762267</td>\n",
       "      <td>legit</td>\n",
       "      <td>0</td>\n",
       "      <td>[7, 2, 32, 17, 5, 27, 6, 13, 20, 6, 6, 21, 21,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>aesuyqwsumkgusaq.org</td>\n",
       "      <td>1</td>\n",
       "      <td>legit</td>\n",
       "      <td>20</td>\n",
       "      <td>3.546439</td>\n",
       "      <td>legit</td>\n",
       "      <td>0</td>\n",
       "      <td>[36, 2, 1, 5, 17, 37, 27, 1, 5, 22, 9, 18, 5, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>dgmplybwo.ru</td>\n",
       "      <td>1</td>\n",
       "      <td>legit</td>\n",
       "      <td>12</td>\n",
       "      <td>3.584963</td>\n",
       "      <td>legit</td>\n",
       "      <td>0</td>\n",
       "      <td>[7, 18, 22, 10, 24, 17, 20, 27, 32, 19, 3, 5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8xqa87v392w1dq4t.com</td>\n",
       "      <td>1</td>\n",
       "      <td>legit</td>\n",
       "      <td>20</td>\n",
       "      <td>4.121928</td>\n",
       "      <td>legit</td>\n",
       "      <td>0</td>\n",
       "      <td>[28, 6, 37, 36, 28, 16, 15, 35, 14, 26, 27, 34...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>u1d59f8470cc1e8ced5e708aada7d7ae47.tk</td>\n",
       "      <td>1</td>\n",
       "      <td>locky</td>\n",
       "      <td>37</td>\n",
       "      <td>3.773793</td>\n",
       "      <td>locky</td>\n",
       "      <td>1</td>\n",
       "      <td>[5, 34, 7, 12, 14, 13, 28, 29, 16, 4, 30, 30, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>mhavnomkzhwdugxam.net</td>\n",
       "      <td>1</td>\n",
       "      <td>locky</td>\n",
       "      <td>21</td>\n",
       "      <td>3.880180</td>\n",
       "      <td>locky</td>\n",
       "      <td>1</td>\n",
       "      <td>[22, 11, 36, 15, 25, 32, 22, 9, 31, 11, 27, 7,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ykasy4mcqciw.com</td>\n",
       "      <td>1</td>\n",
       "      <td>locky</td>\n",
       "      <td>16</td>\n",
       "      <td>3.452820</td>\n",
       "      <td>locky</td>\n",
       "      <td>1</td>\n",
       "      <td>[17, 9, 36, 1, 17, 29, 22, 30, 37, 30, 33, 27,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>p643ec6a49418b7069831a19b0c43c98e0.ws</td>\n",
       "      <td>1</td>\n",
       "      <td>locky</td>\n",
       "      <td>37</td>\n",
       "      <td>3.843796</td>\n",
       "      <td>locky</td>\n",
       "      <td>1</td>\n",
       "      <td>[10, 23, 29, 35, 2, 30, 23, 36, 29, 14, 29, 34...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2udidslsjabeb1terg.ddns.net</td>\n",
       "      <td>1</td>\n",
       "      <td>locky</td>\n",
       "      <td>27</td>\n",
       "      <td>3.810081</td>\n",
       "      <td>locky</td>\n",
       "      <td>1</td>\n",
       "      <td>[26, 5, 7, 33, 7, 1, 24, 1, 8, 36, 20, 2, 20, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0r7d9zqilx6ln7oi.biz</td>\n",
       "      <td>1</td>\n",
       "      <td>locky</td>\n",
       "      <td>20</td>\n",
       "      <td>3.784184</td>\n",
       "      <td>locky</td>\n",
       "      <td>1</td>\n",
       "      <td>[4, 3, 16, 7, 14, 31, 37, 33, 24, 6, 23, 24, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>wr5afpf0w7ifbztx.com</td>\n",
       "      <td>1</td>\n",
       "      <td>locky</td>\n",
       "      <td>20</td>\n",
       "      <td>3.984184</td>\n",
       "      <td>locky</td>\n",
       "      <td>1</td>\n",
       "      <td>[27, 3, 12, 36, 13, 10, 13, 4, 27, 16, 33, 13,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>fzmnbbtqap.com</td>\n",
       "      <td>1</td>\n",
       "      <td>locky</td>\n",
       "      <td>14</td>\n",
       "      <td>3.521641</td>\n",
       "      <td>locky</td>\n",
       "      <td>1</td>\n",
       "      <td>[13, 31, 22, 25, 20, 20, 21, 37, 36, 10, 19, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>yrahramtqrv.dyndns.org</td>\n",
       "      <td>1</td>\n",
       "      <td>locky</td>\n",
       "      <td>22</td>\n",
       "      <td>3.641250</td>\n",
       "      <td>locky</td>\n",
       "      <td>1</td>\n",
       "      <td>[17, 3, 36, 11, 3, 36, 22, 21, 37, 3, 15, 19, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>uiyieen.info</td>\n",
       "      <td>1</td>\n",
       "      <td>locky</td>\n",
       "      <td>12</td>\n",
       "      <td>2.855389</td>\n",
       "      <td>locky</td>\n",
       "      <td>1</td>\n",
       "      <td>[5, 33, 17, 33, 2, 2, 25, 19, 33, 25, 13, 32]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  domains  isdga  actor  length   entropy  \\\n",
       "0                       zba93jwfmthdo.com      1  legit      17  3.852169   \n",
       "1                            thchsnus.xyz      1  legit      12  3.251629   \n",
       "2                         viewedhands.com      1  legit      15  3.640224   \n",
       "3                        4hmjw5q7w9qr.net      1  legit      16  3.750000   \n",
       "4                       norduserforum.com      1  legit      17  3.292770   \n",
       "5                    khhvovnvm.dyndns.org      1  legit      20  3.446439   \n",
       "6                 deoyuwxfbxxtteobqgg.com      1  legit      23  3.762267   \n",
       "7                    aesuyqwsumkgusaq.org      1  legit      20  3.546439   \n",
       "8                            dgmplybwo.ru      1  legit      12  3.584963   \n",
       "9                    8xqa87v392w1dq4t.com      1  legit      20  4.121928   \n",
       "10  u1d59f8470cc1e8ced5e708aada7d7ae47.tk      1  locky      37  3.773793   \n",
       "11                  mhavnomkzhwdugxam.net      1  locky      21  3.880180   \n",
       "13                       ykasy4mcqciw.com      1  locky      16  3.452820   \n",
       "14  p643ec6a49418b7069831a19b0c43c98e0.ws      1  locky      37  3.843796   \n",
       "15            2udidslsjabeb1terg.ddns.net      1  locky      27  3.810081   \n",
       "16                   0r7d9zqilx6ln7oi.biz      1  locky      20  3.784184   \n",
       "17                   wr5afpf0w7ifbztx.com      1  locky      20  3.984184   \n",
       "19                         fzmnbbtqap.com      1  locky      14  3.521641   \n",
       "20                 yrahramtqrv.dyndns.org      1  locky      22  3.641250   \n",
       "21                           uiyieen.info      1  locky      12  2.855389   \n",
       "\n",
       "   classes  class_index                                     domain_indices  \n",
       "0    legit            0  [31, 20, 36, 14, 35, 8, 27, 13, 22, 21, 11, 7,...  \n",
       "1    legit            0       [21, 11, 30, 11, 1, 25, 5, 1, 19, 6, 17, 31]  \n",
       "2    legit            0  [15, 33, 2, 27, 2, 7, 11, 36, 25, 7, 1, 19, 30...  \n",
       "3    legit            0  [29, 11, 22, 8, 27, 12, 37, 16, 27, 14, 37, 3,...  \n",
       "4    legit            0  [25, 32, 3, 7, 5, 1, 2, 3, 13, 32, 3, 5, 22, 1...  \n",
       "5    legit            0  [9, 11, 11, 15, 32, 15, 25, 15, 22, 19, 7, 17,...  \n",
       "6    legit            0  [7, 2, 32, 17, 5, 27, 6, 13, 20, 6, 6, 21, 21,...  \n",
       "7    legit            0  [36, 2, 1, 5, 17, 37, 27, 1, 5, 22, 9, 18, 5, ...  \n",
       "8    legit            0      [7, 18, 22, 10, 24, 17, 20, 27, 32, 19, 3, 5]  \n",
       "9    legit            0  [28, 6, 37, 36, 28, 16, 15, 35, 14, 26, 27, 34...  \n",
       "10   locky            1  [5, 34, 7, 12, 14, 13, 28, 29, 16, 4, 30, 30, ...  \n",
       "11   locky            1  [22, 11, 36, 15, 25, 32, 22, 9, 31, 11, 27, 7,...  \n",
       "13   locky            1  [17, 9, 36, 1, 17, 29, 22, 30, 37, 30, 33, 27,...  \n",
       "14   locky            1  [10, 23, 29, 35, 2, 30, 23, 36, 29, 14, 29, 34...  \n",
       "15   locky            1  [26, 5, 7, 33, 7, 1, 24, 1, 8, 36, 20, 2, 20, ...  \n",
       "16   locky            1  [4, 3, 16, 7, 14, 31, 37, 33, 24, 6, 23, 24, 2...  \n",
       "17   locky            1  [27, 3, 12, 36, 13, 10, 13, 4, 27, 16, 33, 13,...  \n",
       "19   locky            1  [13, 31, 22, 25, 20, 20, 21, 37, 36, 10, 19, 3...  \n",
       "20   locky            1  [17, 3, 36, 11, 3, 36, 22, 21, 37, 3, 15, 19, ...  \n",
       "21   locky            1      [5, 33, 17, 33, 2, 2, 25, 19, 33, 25, 13, 32]  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_small = df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domains</th>\n",
       "      <th>isdga</th>\n",
       "      <th>actor</th>\n",
       "      <th>length</th>\n",
       "      <th>entropy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zba93jwfmthdo.com</td>\n",
       "      <td>1</td>\n",
       "      <td>legit</td>\n",
       "      <td>17</td>\n",
       "      <td>3.852169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>thchsnus.xyz</td>\n",
       "      <td>1</td>\n",
       "      <td>legit</td>\n",
       "      <td>12</td>\n",
       "      <td>3.251629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>viewedhands.com</td>\n",
       "      <td>1</td>\n",
       "      <td>legit</td>\n",
       "      <td>15</td>\n",
       "      <td>3.640224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4hmjw5q7w9qr.net</td>\n",
       "      <td>1</td>\n",
       "      <td>legit</td>\n",
       "      <td>16</td>\n",
       "      <td>3.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>norduserforum.com</td>\n",
       "      <td>1</td>\n",
       "      <td>legit</td>\n",
       "      <td>17</td>\n",
       "      <td>3.292770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>khhvovnvm.dyndns.org</td>\n",
       "      <td>1</td>\n",
       "      <td>legit</td>\n",
       "      <td>20</td>\n",
       "      <td>3.446439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>deoyuwxfbxxtteobqgg.com</td>\n",
       "      <td>1</td>\n",
       "      <td>legit</td>\n",
       "      <td>23</td>\n",
       "      <td>3.762267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>aesuyqwsumkgusaq.org</td>\n",
       "      <td>1</td>\n",
       "      <td>legit</td>\n",
       "      <td>20</td>\n",
       "      <td>3.546439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>dgmplybwo.ru</td>\n",
       "      <td>1</td>\n",
       "      <td>legit</td>\n",
       "      <td>12</td>\n",
       "      <td>3.584963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8xqa87v392w1dq4t.com</td>\n",
       "      <td>1</td>\n",
       "      <td>legit</td>\n",
       "      <td>20</td>\n",
       "      <td>4.121928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>u1d59f8470cc1e8ced5e708aada7d7ae47.tk</td>\n",
       "      <td>1</td>\n",
       "      <td>locky</td>\n",
       "      <td>37</td>\n",
       "      <td>3.773793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>mhavnomkzhwdugxam.net</td>\n",
       "      <td>1</td>\n",
       "      <td>locky</td>\n",
       "      <td>21</td>\n",
       "      <td>3.880180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ykasy4mcqciw.com</td>\n",
       "      <td>1</td>\n",
       "      <td>locky</td>\n",
       "      <td>16</td>\n",
       "      <td>3.452820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>p643ec6a49418b7069831a19b0c43c98e0.ws</td>\n",
       "      <td>1</td>\n",
       "      <td>locky</td>\n",
       "      <td>37</td>\n",
       "      <td>3.843796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2udidslsjabeb1terg.ddns.net</td>\n",
       "      <td>1</td>\n",
       "      <td>locky</td>\n",
       "      <td>27</td>\n",
       "      <td>3.810081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0r7d9zqilx6ln7oi.biz</td>\n",
       "      <td>1</td>\n",
       "      <td>locky</td>\n",
       "      <td>20</td>\n",
       "      <td>3.784184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>wr5afpf0w7ifbztx.com</td>\n",
       "      <td>1</td>\n",
       "      <td>locky</td>\n",
       "      <td>20</td>\n",
       "      <td>3.984184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>fzmnbbtqap.com</td>\n",
       "      <td>1</td>\n",
       "      <td>locky</td>\n",
       "      <td>14</td>\n",
       "      <td>3.521641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>yrahramtqrv.dyndns.org</td>\n",
       "      <td>1</td>\n",
       "      <td>locky</td>\n",
       "      <td>22</td>\n",
       "      <td>3.641250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>uiyieen.info</td>\n",
       "      <td>1</td>\n",
       "      <td>locky</td>\n",
       "      <td>12</td>\n",
       "      <td>2.855389</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  domains  isdga  actor  length   entropy\n",
       "0                       zba93jwfmthdo.com      1  legit      17  3.852169\n",
       "1                            thchsnus.xyz      1  legit      12  3.251629\n",
       "2                         viewedhands.com      1  legit      15  3.640224\n",
       "3                        4hmjw5q7w9qr.net      1  legit      16  3.750000\n",
       "4                       norduserforum.com      1  legit      17  3.292770\n",
       "5                    khhvovnvm.dyndns.org      1  legit      20  3.446439\n",
       "6                 deoyuwxfbxxtteobqgg.com      1  legit      23  3.762267\n",
       "7                    aesuyqwsumkgusaq.org      1  legit      20  3.546439\n",
       "8                            dgmplybwo.ru      1  legit      12  3.584963\n",
       "9                    8xqa87v392w1dq4t.com      1  legit      20  4.121928\n",
       "10  u1d59f8470cc1e8ced5e708aada7d7ae47.tk      1  locky      37  3.773793\n",
       "11                  mhavnomkzhwdugxam.net      1  locky      21  3.880180\n",
       "13                       ykasy4mcqciw.com      1  locky      16  3.452820\n",
       "14  p643ec6a49418b7069831a19b0c43c98e0.ws      1  locky      37  3.843796\n",
       "15            2udidslsjabeb1terg.ddns.net      1  locky      27  3.810081\n",
       "16                   0r7d9zqilx6ln7oi.biz      1  locky      20  3.784184\n",
       "17                   wr5afpf0w7ifbztx.com      1  locky      20  3.984184\n",
       "19                         fzmnbbtqap.com      1  locky      14  3.521641\n",
       "20                 yrahramtqrv.dyndns.org      1  locky      22  3.641250\n",
       "21                           uiyieen.info      1  locky      12  2.855389"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_small.loc[:10, 'actor'] = 'legit'\n",
    "df_small.loc[10:, 'actor'] = 'locky'\n",
    "df_small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37\n"
     ]
    }
   ],
   "source": [
    "MAX_LENGTH = np.max(df_small.domains.apply(len))\n",
    "print(MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([17,  9, 36,  1, 17, 29, 22, 30, 37, 30, 33, 27, 19, 30, 32, 22])\n",
      " array([21, 11, 30, 11,  1, 25,  5,  1, 19,  6, 17, 31])\n",
      " array([22, 11, 36, 15, 25, 32, 22,  9, 31, 11, 27,  7,  5, 18,  6, 36, 22,\n",
      "        19, 25,  2, 21])\n",
      " array([ 5, 34,  7, 12, 14, 13, 28, 29, 16,  4, 30, 30, 34,  2, 28, 30,  2,\n",
      "         7, 12,  2, 16,  4, 28, 36, 36,  7, 36, 16,  7, 16, 36,  2, 29, 16,\n",
      "        19, 21,  9])\n",
      " array([ 7, 18, 22, 10, 24, 17, 20, 27, 32, 19,  3,  5])\n",
      " array([10, 23, 29, 35,  2, 30, 23, 36, 29, 14, 29, 34, 28, 20, 16,  4, 23,\n",
      "        14, 28, 35, 34, 36, 34, 14, 20,  4, 30, 29, 35, 30, 14, 28,  2,  4,\n",
      "        19, 27,  1])\n",
      " array([36,  2,  1,  5, 17, 37, 27,  1,  5, 22,  9, 18,  5,  1, 36, 37, 19,\n",
      "        32,  3, 18])\n",
      " array([ 5, 33, 17, 33,  2,  2, 25, 19, 33, 25, 13, 32])\n",
      " array([28,  6, 37, 36, 28, 16, 15, 35, 14, 26, 27, 34,  7, 37, 29, 21, 19,\n",
      "        30, 32, 22])\n",
      " array([25, 32,  3,  7,  5,  1,  2,  3, 13, 32,  3,  5, 22, 19, 30, 32, 22])\n",
      " array([13, 31, 22, 25, 20, 20, 21, 37, 36, 10, 19, 30, 32, 22])\n",
      " array([17,  3, 36, 11,  3, 36, 22, 21, 37,  3, 15, 19,  7, 17, 25,  7, 25,\n",
      "         1, 19, 32,  3, 18])\n",
      " array([ 9, 11, 11, 15, 32, 15, 25, 15, 22, 19,  7, 17, 25,  7, 25,  1, 19,\n",
      "        32,  3, 18])\n",
      " array([ 4,  3, 16,  7, 14, 31, 37, 33, 24,  6, 23, 24, 25, 16, 32, 33, 19,\n",
      "        20, 33, 31])\n",
      " array([27,  3, 12, 36, 13, 10, 13,  4, 27, 16, 33, 13, 20, 31, 21,  6, 19,\n",
      "        30, 32, 22])\n",
      " array([29, 11, 22,  8, 27, 12, 37, 16, 27, 14, 37,  3, 19, 25,  2, 21])]\n",
      "[1 0 1 1 0 1 0 1 0 0 1 1 0 1 1 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gb/m76n3l_97j92hstc5f4t0ds00000gn/T/ipykernel_12044/2652206494.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_frame['classes'] = data_frame['actor']\n",
      "/var/folders/gb/m76n3l_97j92hstc5f4t0ds00000gn/T/ipykernel_12044/2652206494.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_frame['class_index'] = data_frame['classes'].map(class_to_index)\n",
      "/var/folders/gb/m76n3l_97j92hstc5f4t0ds00000gn/T/ipykernel_12044/2652206494.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_frame['domain_indices'] = data_frame['domains'].apply(lambda x: np.array([char_to_index[char] for char in x]))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type numpy.ndarray).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/daniel/Synology_Ongoing/HES_Data_Science/test/ac2152023_cybersafe/notebooks/model_CNN_LSTM.ipynb Cell 10\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/daniel/Synology_Ongoing/HES_Data_Science/test/ac2152023_cybersafe/notebooks/model_CNN_LSTM.ipynb#X32sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m create_lstm_dataset(df_small, sequence_length\u001b[39m=\u001b[39;49mMAX_LENGTH, batch_size\u001b[39m=\u001b[39;49m\u001b[39m32\u001b[39;49m, validation_split\u001b[39m=\u001b[39;49m\u001b[39m0.2\u001b[39;49m)\n",
      "\u001b[1;32m/Users/daniel/Synology_Ongoing/HES_Data_Science/test/ac2152023_cybersafe/notebooks/model_CNN_LSTM.ipynb Cell 10\u001b[0m line \u001b[0;36m6\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/daniel/Synology_Ongoing/HES_Data_Science/test/ac2152023_cybersafe/notebooks/model_CNN_LSTM.ipynb#X32sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m \u001b[39mprint\u001b[39m(train_sequences)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/daniel/Synology_Ongoing/HES_Data_Science/test/ac2152023_cybersafe/notebooks/model_CNN_LSTM.ipynb#X32sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m \u001b[39mprint\u001b[39m(train_labels)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/daniel/Synology_Ongoing/HES_Data_Science/test/ac2152023_cybersafe/notebooks/model_CNN_LSTM.ipynb#X32sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m train_dataset \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mdata\u001b[39m.\u001b[39;49mDataset\u001b[39m.\u001b[39;49mfrom_tensor_slices((train_sequences, train_labels))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/daniel/Synology_Ongoing/HES_Data_Science/test/ac2152023_cybersafe/notebooks/model_CNN_LSTM.ipynb#X32sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m val_dataset \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataset\u001b[39m.\u001b[39mfrom_tensor_slices((val_sequences, val_labels))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/daniel/Synology_Ongoing/HES_Data_Science/test/ac2152023_cybersafe/notebooks/model_CNN_LSTM.ipynb#X32sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m \u001b[39m# Batch and shuffle the datasets\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ac215_tf/lib/python3.11/site-packages/tensorflow/python/data/ops/dataset_ops.py:821\u001b[0m, in \u001b[0;36mDatasetV2.from_tensor_slices\u001b[0;34m(tensors, name)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[39m# Loaded lazily due to a circular dependency (dataset_ops ->\u001b[39;00m\n\u001b[1;32m    818\u001b[0m \u001b[39m# from_tensor_slices_op -> dataset_ops).\u001b[39;00m\n\u001b[1;32m    819\u001b[0m \u001b[39m# pylint: disable=g-import-not-at-top,protected-access\u001b[39;00m\n\u001b[1;32m    820\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mops\u001b[39;00m \u001b[39mimport\u001b[39;00m from_tensor_slices_op\n\u001b[0;32m--> 821\u001b[0m \u001b[39mreturn\u001b[39;00m from_tensor_slices_op\u001b[39m.\u001b[39;49m_from_tensor_slices(tensors, name)\n",
      "File \u001b[0;32m~/anaconda3/envs/ac215_tf/lib/python3.11/site-packages/tensorflow/python/data/ops/from_tensor_slices_op.py:25\u001b[0m, in \u001b[0;36m_from_tensor_slices\u001b[0;34m(tensors, name)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_from_tensor_slices\u001b[39m(tensors, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m---> 25\u001b[0m   \u001b[39mreturn\u001b[39;00m _TensorSliceDataset(tensors, name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[0;32m~/anaconda3/envs/ac215_tf/lib/python3.11/site-packages/tensorflow/python/data/ops/from_tensor_slices_op.py:33\u001b[0m, in \u001b[0;36m_TensorSliceDataset.__init__\u001b[0;34m(self, element, is_files, name)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, element, is_files\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m     32\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"See `Dataset.from_tensor_slices` for details.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m   element \u001b[39m=\u001b[39m structure\u001b[39m.\u001b[39;49mnormalize_element(element)\n\u001b[1;32m     34\u001b[0m   batched_spec \u001b[39m=\u001b[39m structure\u001b[39m.\u001b[39mtype_spec_from_value(element)\n\u001b[1;32m     35\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tensors \u001b[39m=\u001b[39m structure\u001b[39m.\u001b[39mto_batched_tensor_list(batched_spec, element)\n",
      "File \u001b[0;32m~/anaconda3/envs/ac215_tf/lib/python3.11/site-packages/tensorflow/python/data/util/structure.py:134\u001b[0m, in \u001b[0;36mnormalize_element\u001b[0;34m(element, element_signature)\u001b[0m\n\u001b[1;32m    131\u001b[0m       \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    132\u001b[0m         dtype \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(spec, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m    133\u001b[0m         normalized_components\u001b[39m.\u001b[39mappend(\n\u001b[0;32m--> 134\u001b[0m             ops\u001b[39m.\u001b[39;49mconvert_to_tensor(t, name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcomponent_\u001b[39;49m\u001b[39m%d\u001b[39;49;00m\u001b[39m\"\u001b[39;49m \u001b[39m%\u001b[39;49m i, dtype\u001b[39m=\u001b[39;49mdtype))\n\u001b[1;32m    135\u001b[0m \u001b[39mreturn\u001b[39;00m nest\u001b[39m.\u001b[39mpack_sequence_as(pack_as, normalized_components)\n",
      "File \u001b[0;32m~/anaconda3/envs/ac215_tf/lib/python3.11/site-packages/tensorflow/python/profiler/trace.py:183\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m   \u001b[39mwith\u001b[39;00m Trace(trace_name, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtrace_kwargs):\n\u001b[1;32m    182\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 183\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/ac215_tf/lib/python3.11/site-packages/tensorflow/python/framework/ops.py:698\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[39m# TODO(b/142518781): Fix all call-sites and remove redundant arg\u001b[39;00m\n\u001b[1;32m    697\u001b[0m preferred_dtype \u001b[39m=\u001b[39m preferred_dtype \u001b[39mor\u001b[39;00m dtype_hint\n\u001b[0;32m--> 698\u001b[0m \u001b[39mreturn\u001b[39;00m tensor_conversion_registry\u001b[39m.\u001b[39;49mconvert(\n\u001b[1;32m    699\u001b[0m     value, dtype, name, as_ref, preferred_dtype, accepted_result_types\n\u001b[1;32m    700\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/ac215_tf/lib/python3.11/site-packages/tensorflow/python/framework/tensor_conversion_registry.py:234\u001b[0m, in \u001b[0;36mconvert\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, accepted_result_types)\u001b[0m\n\u001b[1;32m    225\u001b[0m       \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    226\u001b[0m           _add_error_prefix(\n\u001b[1;32m    227\u001b[0m               \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mConversion function \u001b[39m\u001b[39m{\u001b[39;00mconversion_func\u001b[39m!r}\u001b[39;00m\u001b[39m for type \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    230\u001b[0m               \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mactual = \u001b[39m\u001b[39m{\u001b[39;00mret\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mbase_dtype\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    231\u001b[0m               name\u001b[39m=\u001b[39mname))\n\u001b[1;32m    233\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 234\u001b[0m   ret \u001b[39m=\u001b[39m conversion_func(value, dtype\u001b[39m=\u001b[39;49mdtype, name\u001b[39m=\u001b[39;49mname, as_ref\u001b[39m=\u001b[39;49mas_ref)\n\u001b[1;32m    236\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39mis\u001b[39;00m \u001b[39mNotImplemented\u001b[39m:\n\u001b[1;32m    237\u001b[0m   \u001b[39mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ac215_tf/lib/python3.11/site-packages/tensorflow/python/framework/constant_op.py:328\u001b[0m, in \u001b[0;36m_constant_tensor_conversion_function\u001b[0;34m(v, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_constant_tensor_conversion_function\u001b[39m(v, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    326\u001b[0m                                          as_ref\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    327\u001b[0m   _ \u001b[39m=\u001b[39m as_ref\n\u001b[0;32m--> 328\u001b[0m   \u001b[39mreturn\u001b[39;00m constant(v, dtype\u001b[39m=\u001b[39;49mdtype, name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[0;32m~/anaconda3/envs/ac215_tf/lib/python3.11/site-packages/tensorflow/python/framework/constant_op.py:267\u001b[0m, in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mconstant\u001b[39m\u001b[39m\"\u001b[39m, v1\u001b[39m=\u001b[39m[])\n\u001b[1;32m    171\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconstant\u001b[39m(value, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, shape\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mConst\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    172\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[1;32m    173\u001b[0m \n\u001b[1;32m    174\u001b[0m \u001b[39m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[39m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[1;32m    266\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m   \u001b[39mreturn\u001b[39;00m _constant_impl(value, dtype, shape, name, verify_shape\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    268\u001b[0m                         allow_broadcast\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/ac215_tf/lib/python3.11/site-packages/tensorflow/python/framework/constant_op.py:279\u001b[0m, in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[39mwith\u001b[39;00m trace\u001b[39m.\u001b[39mTrace(\u001b[39m\"\u001b[39m\u001b[39mtf.constant\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    278\u001b[0m       \u001b[39mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[0;32m--> 279\u001b[0m   \u001b[39mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[1;32m    281\u001b[0m const_tensor \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39m_create_graph_constant(  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    282\u001b[0m     value, dtype, shape, name, verify_shape, allow_broadcast\n\u001b[1;32m    283\u001b[0m )\n\u001b[1;32m    284\u001b[0m \u001b[39mreturn\u001b[39;00m const_tensor\n",
      "File \u001b[0;32m~/anaconda3/envs/ac215_tf/lib/python3.11/site-packages/tensorflow/python/framework/constant_op.py:289\u001b[0m, in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_constant_eager_impl\u001b[39m(ctx, value, dtype, shape, verify_shape):\n\u001b[1;32m    288\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Creates a constant on the current device.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m   t \u001b[39m=\u001b[39m convert_to_eager_tensor(value, ctx, dtype)\n\u001b[1;32m    290\u001b[0m   \u001b[39mif\u001b[39;00m shape \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    291\u001b[0m     \u001b[39mreturn\u001b[39;00m t\n",
      "File \u001b[0;32m~/anaconda3/envs/ac215_tf/lib/python3.11/site-packages/tensorflow/python/framework/constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    100\u001b[0m     dtype \u001b[39m=\u001b[39m dtypes\u001b[39m.\u001b[39mas_dtype(dtype)\u001b[39m.\u001b[39mas_datatype_enum\n\u001b[1;32m    101\u001b[0m ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 102\u001b[0m \u001b[39mreturn\u001b[39;00m ops\u001b[39m.\u001b[39;49mEagerTensor(value, ctx\u001b[39m.\u001b[39;49mdevice_name, dtype)\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type numpy.ndarray)."
     ]
    }
   ],
   "source": [
    "create_lstm_dataset(df_small, sequence_length=MAX_LENGTH, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tf_dataset(domains):\n",
    "  vocab = sorted(set(''.join(domains['domain'].to_list())))\n",
    "  char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "  idx2char = np.array(vocab)\n",
    "\n",
    "  lines = []\n",
    "  for i, line in enumerate(domains.iloc[:, 0]):\n",
    "    lines.append([char2idx[c] for c in line])\n",
    "  \n",
    "  tensor = tf.keras.preprocessing.sequence.pad_sequences(lines, padding='post')\n",
    "\n",
    "  # Label Encoding\n",
    "  le = LabelEncoder()\n",
    "  le.fit(domains.iloc[:, 1])\n",
    "  \n",
    "  Y_values_le = le.transform(domains.iloc[:, 1])\n",
    "\n",
    "  targets = Y_values_le #np.array(domains.iloc[:, 1], dtype=np.int32)\n",
    "\n",
    "  data = tf.data.Dataset.from_tensor_slices(tensor)\n",
    "  pred = tf.data.Dataset.from_tensor_slices(targets)\n",
    "  dataset = tf.data.Dataset.from_tensor_slices((tensor, targets))\n",
    "  \n",
    "  return dataset, (char2idx, idx2char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tf_dataset(domains):\n",
    "  vocab = sorted(set(''.join(domains['domains'].to_list())))\n",
    "  char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "  idx2char = np.array(vocab)\n",
    "\n",
    "  lines = []\n",
    "  for i, line in enumerate(domains.iloc[:, 0]):\n",
    "    lines.append([char2idx[c] for c in line])\n",
    "  \n",
    "  tensor = tf.keras.preprocessing.sequence.pad_sequences(lines, padding='pre')\n",
    "\n",
    "\n",
    "  targets = domains['actor'].astype('category').cat.codes.values\n",
    "\n",
    "\n",
    "  data = tf.data.Dataset.from_tensor_slices(tensor)\n",
    "  pred = tf.data.Dataset.from_tensor_slices(targets)\n",
    "  dataset = tf.data.Dataset.from_tensor_slices((tensor, targets))\n",
    "  \n",
    "  return dataset #, (char2idx, idx2char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0, shape=(), dtype=int8)\n",
      "tf.Tensor(0, shape=(), dtype=int8)\n",
      "tf.Tensor(0, shape=(), dtype=int8)\n",
      "tf.Tensor(0, shape=(), dtype=int8)\n",
      "tf.Tensor(0, shape=(), dtype=int8)\n",
      "tf.Tensor(0, shape=(), dtype=int8)\n",
      "tf.Tensor(0, shape=(), dtype=int8)\n",
      "tf.Tensor(0, shape=(), dtype=int8)\n",
      "tf.Tensor(0, shape=(), dtype=int8)\n",
      "tf.Tensor(0, shape=(), dtype=int8)\n",
      "tf.Tensor(1, shape=(), dtype=int8)\n",
      "tf.Tensor(1, shape=(), dtype=int8)\n",
      "tf.Tensor(1, shape=(), dtype=int8)\n",
      "tf.Tensor(1, shape=(), dtype=int8)\n",
      "tf.Tensor(1, shape=(), dtype=int8)\n",
      "tf.Tensor(1, shape=(), dtype=int8)\n",
      "tf.Tensor(1, shape=(), dtype=int8)\n",
      "tf.Tensor(1, shape=(), dtype=int8)\n",
      "tf.Tensor(1, shape=(), dtype=int8)\n",
      "tf.Tensor(1, shape=(), dtype=int8)\n"
     ]
    }
   ],
   "source": [
    "for x, y in load_tf_dataset(df_small):\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>domain</th>\n",
       "      <th>actor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zba93jwfmthdo.com</td>\n",
       "      <td>shiotob</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>thchsnus.xyz</td>\n",
       "      <td>locky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>viewedhands.com</td>\n",
       "      <td>nymaim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4hmjw5q7w9qr.net</td>\n",
       "      <td>qadars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>norduserforum.com</td>\n",
       "      <td>legit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299995</th>\n",
       "      <td>mjgwmji3ntga.com</td>\n",
       "      <td>sisron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299996</th>\n",
       "      <td>aawekoacqacqoeqa.org</td>\n",
       "      <td>ramdo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299997</th>\n",
       "      <td>bend-race-choice.com</td>\n",
       "      <td>matsnu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299998</th>\n",
       "      <td>ocmgiqasywemcgsw.org</td>\n",
       "      <td>ramdo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299999</th>\n",
       "      <td>isandarefordictateto.com</td>\n",
       "      <td>rovnix</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          domain    actor\n",
       "0              zba93jwfmthdo.com  shiotob\n",
       "1                   thchsnus.xyz    locky\n",
       "2                viewedhands.com   nymaim\n",
       "3               4hmjw5q7w9qr.net   qadars\n",
       "4              norduserforum.com    legit\n",
       "...                          ...      ...\n",
       "299995          mjgwmji3ntga.com   sisron\n",
       "299996      aawekoacqacqoeqa.org    ramdo\n",
       "299997      bend-race-choice.com   matsnu\n",
       "299998      ocmgiqasywemcgsw.org    ramdo\n",
       "299999  isandarefordictateto.com   rovnix\n",
       "\n",
       "[300000 rows x 2 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size_N = 300_000\n",
    "df = df.reset_index(drop=True)\n",
    "domains = df[['domains', 'actor']].iloc[:size_N]\n",
    "domains['domain'] = domains['domains']\n",
    "domains = domains[['domain', 'actor']]\n",
    "domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n"
     ]
    }
   ],
   "source": [
    "MAX_LENGTH = np.max(domains.domain.apply(len))\n",
    "print(MAX_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, mappings = load_tf_dataset(domains)\n",
    "char2idx, idx2char = mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into train and test sets\n",
    "train_size = int(size_N * 0.9)\n",
    "test_size = len(df) - train_size\n",
    "\n",
    "train_dataset = dataset.take(train_size).batch(batch_size=1500)\n",
    "test_dataset = dataset.skip(train_size).batch(batch_size=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([1500, 62])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_batch = next(iter(train_dataset.take(1)))\n",
    "first_component = first_batch[0]\n",
    "first_component.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset = dataset.batch(1500, drop_remainder=True)\n",
    "# test_dataset = test_dataset.batch(1500, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "  domain_input = Input(shape=(MAX_LENGTH,), dtype='int32', name='domain_input')\n",
    "  embedding = Embedding(input_dim=39, output_dim=128, input_length=MAX_LENGTH, \n",
    "                        batch_input_shape=[1500, None])(domain_input)\n",
    "  conv = Conv1D(filters=128, kernel_size=3, padding='same', activation='relu', strides=1)(embedding)\n",
    "  pool = MaxPooling1D(pool_size=2, padding='same')(conv)\n",
    "  lstm = LSTM(64, return_sequences=False)(pool)\n",
    "  drop = Dropout(0.5)(lstm)\n",
    "  output = Dense(1, activation='softmax')(drop)\n",
    "  model = tf.keras.Model(inputs=domain_input, outputs=output)\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " domain_input (InputLayer)   [(None, 62)]              0         \n",
      "                                                                 \n",
      " embedding_3 (Embedding)     (None, 62, 128)           4992      \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 62, 128)           49280     \n",
      "                                                                 \n",
      " max_pooling1d_3 (MaxPoolin  (None, 31, 128)           0         \n",
      " g1D)                                                            \n",
      "                                                                 \n",
      " lstm_3 (LSTM)               (None, 64)                49408     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 103745 (405.25 KB)\n",
      "Trainable params: 103745 (405.25 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      " 35/180 [====>.........................] - ETA: 1:05 - loss: 0.0000e+00 - accuracy: 0.0316"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/daniel/Synology_Ongoing/HES_Data_Science/test/ac2152023_cybersafe/notebooks/model_CNN_LSTM.ipynb Cell 16\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/daniel/Synology_Ongoing/HES_Data_Science/test/ac2152023_cybersafe/notebooks/model_CNN_LSTM.ipynb#X21sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m accuracy \u001b[39m=\u001b[39m []\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/daniel/Synology_Ongoing/HES_Data_Science/test/ac2152023_cybersafe/notebooks/model_CNN_LSTM.ipynb#X21sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m losses \u001b[39m=\u001b[39m []\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/daniel/Synology_Ongoing/HES_Data_Science/test/ac2152023_cybersafe/notebooks/model_CNN_LSTM.ipynb#X21sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(train_dataset, validation_data\u001b[39m=\u001b[39;49mtest_dataset, epochs\u001b[39m=\u001b[39;49mEPOCHS)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/daniel/Synology_Ongoing/HES_Data_Science/test/ac2152023_cybersafe/notebooks/model_CNN_LSTM.ipynb#X21sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m   \u001b[39m# accuracy.append(history.history['accuracy'])\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/daniel/Synology_Ongoing/HES_Data_Science/test/ac2152023_cybersafe/notebooks/model_CNN_LSTM.ipynb#X21sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m   \u001b[39m# losses.append(history.history['loss'])\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ac215_tf/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/anaconda3/envs/ac215_tf/lib/python3.11/site-packages/keras/src/engine/training.py:1789\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1787\u001b[0m logs \u001b[39m=\u001b[39m tmp_logs\n\u001b[1;32m   1788\u001b[0m end_step \u001b[39m=\u001b[39m step \u001b[39m+\u001b[39m data_handler\u001b[39m.\u001b[39mstep_increment\n\u001b[0;32m-> 1789\u001b[0m callbacks\u001b[39m.\u001b[39;49mon_train_batch_end(end_step, logs)\n\u001b[1;32m   1790\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstop_training:\n\u001b[1;32m   1791\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/ac215_tf/lib/python3.11/site-packages/keras/src/callbacks.py:475\u001b[0m, in \u001b[0;36mCallbackList.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    468\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Calls the `on_train_batch_end` methods of its callbacks.\u001b[39;00m\n\u001b[1;32m    469\u001b[0m \n\u001b[1;32m    470\u001b[0m \u001b[39mArgs:\u001b[39;00m\n\u001b[1;32m    471\u001b[0m \u001b[39m    batch: Integer, index of batch within the current epoch.\u001b[39;00m\n\u001b[1;32m    472\u001b[0m \u001b[39m    logs: Dict. Aggregated metric results up until this batch.\u001b[39;00m\n\u001b[1;32m    473\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_call_train_batch_hooks:\n\u001b[0;32m--> 475\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_hook(ModeKeys\u001b[39m.\u001b[39;49mTRAIN, \u001b[39m\"\u001b[39;49m\u001b[39mend\u001b[39;49m\u001b[39m\"\u001b[39;49m, batch, logs\u001b[39m=\u001b[39;49mlogs)\n",
      "File \u001b[0;32m~/anaconda3/envs/ac215_tf/lib/python3.11/site-packages/keras/src/callbacks.py:322\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_batch_begin_hook(mode, batch, logs)\n\u001b[1;32m    321\u001b[0m \u001b[39melif\u001b[39;00m hook \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mend\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m--> 322\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_end_hook(mode, batch, logs)\n\u001b[1;32m    323\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    324\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    325\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnrecognized hook: \u001b[39m\u001b[39m{\u001b[39;00mhook\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    326\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mExpected values are [\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mbegin\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39mend\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m]\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    327\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/ac215_tf/lib/python3.11/site-packages/keras/src/callbacks.py:345\u001b[0m, in \u001b[0;36mCallbackList._call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     batch_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_start_time\n\u001b[1;32m    343\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_times\u001b[39m.\u001b[39mappend(batch_time)\n\u001b[0;32m--> 345\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_batch_hook_helper(hook_name, batch, logs)\n\u001b[1;32m    347\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_batch_times) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_batches_for_timing_check:\n\u001b[1;32m    348\u001b[0m     end_hook_name \u001b[39m=\u001b[39m hook_name\n",
      "File \u001b[0;32m~/anaconda3/envs/ac215_tf/lib/python3.11/site-packages/keras/src/callbacks.py:393\u001b[0m, in \u001b[0;36mCallbackList._call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[39mfor\u001b[39;00m callback \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallbacks:\n\u001b[1;32m    392\u001b[0m     hook \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(callback, hook_name)\n\u001b[0;32m--> 393\u001b[0m     hook(batch, logs)\n\u001b[1;32m    395\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_timing:\n\u001b[1;32m    396\u001b[0m     \u001b[39mif\u001b[39;00m hook_name \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_hook_times:\n",
      "File \u001b[0;32m~/anaconda3/envs/ac215_tf/lib/python3.11/site-packages/keras/src/callbacks.py:1093\u001b[0m, in \u001b[0;36mProgbarLogger.on_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1092\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mon_train_batch_end\u001b[39m(\u001b[39mself\u001b[39m, batch, logs\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m-> 1093\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_batch_update_progbar(batch, logs)\n",
      "File \u001b[0;32m~/anaconda3/envs/ac215_tf/lib/python3.11/site-packages/keras/src/callbacks.py:1169\u001b[0m, in \u001b[0;36mProgbarLogger._batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1165\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseen \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m add_seen\n\u001b[1;32m   1167\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   1168\u001b[0m     \u001b[39m# Only block async when verbose = 1.\u001b[39;00m\n\u001b[0;32m-> 1169\u001b[0m     logs \u001b[39m=\u001b[39m tf_utils\u001b[39m.\u001b[39;49msync_to_numpy_or_python_type(logs)\n\u001b[1;32m   1170\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprogbar\u001b[39m.\u001b[39mupdate(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mseen, \u001b[39mlist\u001b[39m(logs\u001b[39m.\u001b[39mitems()), finalize\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/ac215_tf/lib/python3.11/site-packages/keras/src/utils/tf_utils.py:694\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[39mreturn\u001b[39;00m t\n\u001b[1;32m    692\u001b[0m     \u001b[39mreturn\u001b[39;00m t\u001b[39m.\u001b[39mitem() \u001b[39mif\u001b[39;00m np\u001b[39m.\u001b[39mndim(t) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m t\n\u001b[0;32m--> 694\u001b[0m \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49mnest\u001b[39m.\u001b[39;49mmap_structure(_to_single_numpy_or_python_type, tensors)\n",
      "File \u001b[0;32m~/anaconda3/envs/ac215_tf/lib/python3.11/site-packages/tensorflow/python/util/nest.py:629\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    543\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mnest.map_structure\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    544\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmap_structure\u001b[39m(func, \u001b[39m*\u001b[39mstructure, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    545\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Creates a new structure by applying `func` to each atom in `structure`.\u001b[39;00m\n\u001b[1;32m    546\u001b[0m \n\u001b[1;32m    547\u001b[0m \u001b[39m  Refer to [tf.nest](https://www.tensorflow.org/api_docs/python/tf/nest)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[39m    ValueError: If wrong keyword arguments are provided.\u001b[39;00m\n\u001b[1;32m    628\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 629\u001b[0m   \u001b[39mreturn\u001b[39;00m nest_util\u001b[39m.\u001b[39;49mmap_structure(\n\u001b[1;32m    630\u001b[0m       nest_util\u001b[39m.\u001b[39;49mModality\u001b[39m.\u001b[39;49mCORE, func, \u001b[39m*\u001b[39;49mstructure, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    631\u001b[0m   )\n",
      "File \u001b[0;32m~/anaconda3/envs/ac215_tf/lib/python3.11/site-packages/tensorflow/python/util/nest_util.py:1168\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(modality, func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m   1071\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Creates a new structure by applying `func` to each atom in `structure`.\u001b[39;00m\n\u001b[1;32m   1072\u001b[0m \n\u001b[1;32m   1073\u001b[0m \u001b[39m- For Modality.CORE: Refer to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1165\u001b[0m \u001b[39m  ValueError: If wrong keyword arguments are provided.\u001b[39;00m\n\u001b[1;32m   1166\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   1167\u001b[0m \u001b[39mif\u001b[39;00m modality \u001b[39m==\u001b[39m Modality\u001b[39m.\u001b[39mCORE:\n\u001b[0;32m-> 1168\u001b[0m   \u001b[39mreturn\u001b[39;00m _tf_core_map_structure(func, \u001b[39m*\u001b[39;49mstructure, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1169\u001b[0m \u001b[39melif\u001b[39;00m modality \u001b[39m==\u001b[39m Modality\u001b[39m.\u001b[39mDATA:\n\u001b[1;32m   1170\u001b[0m   \u001b[39mreturn\u001b[39;00m _tf_data_map_structure(func, \u001b[39m*\u001b[39mstructure, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/ac215_tf/lib/python3.11/site-packages/tensorflow/python/util/nest_util.py:1208\u001b[0m, in \u001b[0;36m_tf_core_map_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m   1203\u001b[0m flat_structure \u001b[39m=\u001b[39m (_tf_core_flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[1;32m   1204\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[1;32m   1206\u001b[0m \u001b[39mreturn\u001b[39;00m _tf_core_pack_sequence_as(\n\u001b[1;32m   1207\u001b[0m     structure[\u001b[39m0\u001b[39m],\n\u001b[0;32m-> 1208\u001b[0m     [func(\u001b[39m*\u001b[39;49mx) \u001b[39mfor\u001b[39;49;00m x \u001b[39min\u001b[39;49;00m entries],\n\u001b[1;32m   1209\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites,\n\u001b[1;32m   1210\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/ac215_tf/lib/python3.11/site-packages/tensorflow/python/util/nest_util.py:1208\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1203\u001b[0m flat_structure \u001b[39m=\u001b[39m (_tf_core_flatten(s, expand_composites) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m structure)\n\u001b[1;32m   1204\u001b[0m entries \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39mflat_structure)\n\u001b[1;32m   1206\u001b[0m \u001b[39mreturn\u001b[39;00m _tf_core_pack_sequence_as(\n\u001b[1;32m   1207\u001b[0m     structure[\u001b[39m0\u001b[39m],\n\u001b[0;32m-> 1208\u001b[0m     [func(\u001b[39m*\u001b[39;49mx) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m entries],\n\u001b[1;32m   1209\u001b[0m     expand_composites\u001b[39m=\u001b[39mexpand_composites,\n\u001b[1;32m   1210\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/ac215_tf/lib/python3.11/site-packages/keras/src/utils/tf_utils.py:687\u001b[0m, in \u001b[0;36msync_to_numpy_or_python_type.<locals>._to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    684\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_to_single_numpy_or_python_type\u001b[39m(t):\n\u001b[1;32m    685\u001b[0m     \u001b[39m# Don't turn ragged or sparse tensors to NumPy.\u001b[39;00m\n\u001b[1;32m    686\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(t, tf\u001b[39m.\u001b[39mTensor):\n\u001b[0;32m--> 687\u001b[0m         t \u001b[39m=\u001b[39m t\u001b[39m.\u001b[39;49mnumpy()\n\u001b[1;32m    688\u001b[0m     \u001b[39m# Strings, ragged and sparse tensors don't have .item(). Return them\u001b[39;00m\n\u001b[1;32m    689\u001b[0m     \u001b[39m# as-is.\u001b[39;00m\n\u001b[1;32m    690\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(t, (np\u001b[39m.\u001b[39mndarray, np\u001b[39m.\u001b[39mgeneric)):\n",
      "File \u001b[0;32m~/anaconda3/envs/ac215_tf/lib/python3.11/site-packages/tensorflow/python/framework/ops.py:396\u001b[0m, in \u001b[0;36m_EagerTensorBase.numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Copy of the contents of this Tensor into a NumPy array or scalar.\u001b[39;00m\n\u001b[1;32m    374\u001b[0m \n\u001b[1;32m    375\u001b[0m \u001b[39mUnlike NumPy arrays, Tensors are immutable, so this method has to copy\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[39m    NumPy dtype.\u001b[39;00m\n\u001b[1;32m    394\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    395\u001b[0m \u001b[39m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[39;00m\n\u001b[0;32m--> 396\u001b[0m maybe_arr \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    397\u001b[0m \u001b[39mreturn\u001b[39;00m maybe_arr\u001b[39m.\u001b[39mcopy() \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(maybe_arr, np\u001b[39m.\u001b[39mndarray) \u001b[39melse\u001b[39;00m maybe_arr\n",
      "File \u001b[0;32m~/anaconda3/envs/ac215_tf/lib/python3.11/site-packages/tensorflow/python/framework/ops.py:362\u001b[0m, in \u001b[0;36m_EagerTensorBase._numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_numpy\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    361\u001b[0m   \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 362\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_numpy_internal()\n\u001b[1;32m    363\u001b[0m   \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m    364\u001b[0m     \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EPOCHS = 6 \n",
    "accuracy = []\n",
    "losses = []\n",
    "\n",
    "history = model.fit(train_dataset, validation_data=test_dataset, epochs=EPOCHS)\n",
    "\n",
    "  # accuracy.append(history.history['accuracy'])\n",
    "  # losses.append(history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Initialize a W&B run\n",
    "# Login into wandb\n",
    "# wandb.login(key='cb8f805fb5fb66d45b67a3aeb2fa5bb9c5cef739')\n",
    "# Initialize wandb\n",
    "\n",
    "model_name = 'DecisionTreeClassifier'\n",
    "n_estimators = 10 # for RandomForestClassifier\n",
    "\n",
    "# run = wandb.init(project=GCP_PROJECT, entity='ac2152023_cybersafe', name=model_name, config={\"model_name\": model_name})\n",
    "\n",
    "# Define a function to train a decision tree with various parameters\n",
    "def train_decision_tree(params):\n",
    "    if model_name == 'RandomForestClassifier':\n",
    "        model = RandomForestClassifier(**params)\n",
    "    if model_name == 'DecisionTreeClassifier':\n",
    "        model = DecisionTreeClassifier(**params)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "# Generate all possible combinations of parameters\n",
    "param_grid = {\n",
    "    \"criterion\" : ['entropy'],\n",
    "    \"max_depth\": [4],\n",
    "    \"min_samples_split\": [10],\n",
    "    \"min_samples_leaf\": [5]\n",
    "}\n",
    "all_combinations = itertools.product(*param_grid.values())\n",
    "\n",
    "# Train a decision tree with each combination of parameters\n",
    "for combination in all_combinations:\n",
    "\n",
    "    # Start the timer\n",
    "    start_time = time.time()\n",
    "\n",
    "    params = dict(zip(param_grid.keys(),combination))\n",
    "    if model_name == 'RandomForestClassifier':\n",
    "        params['n_estimators'] = n_estimators\n",
    "    \n",
    "    model = train_decision_tree(params)\n",
    "    # Evaluate the model on the test set\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = np.mean(y_pred == y_test)\n",
    "    \n",
    "    # Calculate the execution time\n",
    "    end_time = time.time()\n",
    "    execution_time = end_time - start_time\n",
    "\n",
    "    # Log the results to wandb\n",
    "    # wandb.log({\"accuracy\": accuracy, \"params\": params, \"execution_time\": execution_time})\n",
    "\n",
    "# Close wandb\n",
    "# wandb.finish()\n",
    "\n",
    "\n",
    "logging.debug(\"Training Job Complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "tree.plot_tree(model)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ac215",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
