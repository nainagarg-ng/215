{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "ZPc6EpZlZLUu"
      },
      "outputs": [],
      "source": [
        "#!pip install google-cloud-secret-manager\n",
        "#!pip install tensorflow_decision_forests\n",
        "#!pip install -q wandb\n",
        "#######THIS NOTEBOOK USES ONLY SIX UNINTERESTING FEATURES USED MERELY AS A BASELINE#####"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "u9GpcCAJH5st"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import dask.dataframe as dd\n",
        "from google.cloud import secretmanager\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import tensorflow_decision_forests as tfdf\n",
        "from datetime import datetime\n",
        "import wandb\n",
        "from wandb.keras import WandbCallback, WandbMetricsLogger"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "WaA5cXYcgEk8"
      },
      "outputs": [],
      "source": [
        "#authenticate self as google user that is connected to GCP cloud account with secret manager access\n",
        "import sys\n",
        "if \"google.colab\" in sys.modules:\n",
        "    from google.colab import auth\n",
        "    auth.authenticate_user()\n",
        "\n",
        "#key value of my secret\n",
        "secret_name = \"harvardmlops_json\"\n",
        "\n",
        "#name of the GCP project\n",
        "project_id = 'harvardmlops'\n",
        "\n",
        "#name of GCP bucket\n",
        "bucket_name = \"harvardmlops\"\n",
        "\n",
        "#name of bucket folder to read\n",
        "gold_folder = \"gold\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "mrmir_2gbapo"
      },
      "outputs": [],
      "source": [
        "# Create a local secrets manager client:\n",
        "client = secretmanager.SecretManagerServiceClient()\n",
        "\n",
        "# resource F string\n",
        "resource_name = f\"projects/{project_id}/secrets/{secret_name}/versions/latest\"\n",
        "\n",
        "# ask the client to get my secret\n",
        "response = client.access_secret_version(request={\"name\": resource_name})\n",
        "\n",
        "#decode the response\n",
        "secret_string = response.payload.data.decode('UTF-8')\n",
        "\n",
        "#token access\n",
        "token = json.loads(secret_string)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "tUQPRXn1d_tf"
      },
      "outputs": [],
      "source": [
        "def read(files):\n",
        "\n",
        "    #storage option paramenter\n",
        "    storage_options={'token': token}\n",
        "\n",
        "    #begin time\n",
        "    start = datetime.now()\n",
        "\n",
        "    #read files as parquest\n",
        "    df = dd.read_parquet(files, storage_options=storage_options)\n",
        "\n",
        "    #stop timing\n",
        "    end = datetime.now()\n",
        "\n",
        "    #give time result\n",
        "    print(f\"Read data from in GCP bucket in: {end-start}\")\n",
        "\n",
        "    #ensure domain is str\n",
        "    df['domains'] = df['domains'].astype(str)\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TB8RGKCNHpaH",
        "outputId": "a6c062fb-99a3-442f-d3df-c188ccca267e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Read data from in GCP bucket in: 0:00:02.930732\n"
          ]
        }
      ],
      "source": [
        "#location of GCP bucket/folder\n",
        "files = f\"gs://{bucket_name}/{gold_folder}/*/*/*.gzip\"\n",
        "\n",
        "#read files into a dask dataframe\n",
        "df = read(files)\n",
        "\n",
        "#convert to pandas DF for first transformation\n",
        "pandas_df = df.compute()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "id": "FS7dhu2BLtY_"
      },
      "outputs": [],
      "source": [
        "def split_data(data, test_size=0.05, validation_size=0.05):\n",
        "\n",
        "    if test_size + validation_size >= 1.0:\n",
        "        raise ValueError(\"The sum of test_size and validation_size must be less than 1.0.\")\n",
        "\n",
        "    # Calculate the remaining percentage for training data\n",
        "    train_size = 1.0 - test_size - validation_size\n",
        "\n",
        "    # Split the data into training and remaining\n",
        "    train_data, remaining_data = train_test_split(data, train_size=train_size, random_state=42)\n",
        "\n",
        "    # Split the remaining data into validation and test\n",
        "    validation_data, test_data = train_test_split(remaining_data, test_size=test_size / (test_size + validation_size), random_state=42)\n",
        "\n",
        "    return train_data, validation_data, test_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "id": "rGb2Q7-6MHnq"
      },
      "outputs": [],
      "source": [
        "# get training, valiation, and test data\n",
        "train_data, validation_data, test_data = split_data(pandas_df)\n",
        "\n",
        "#attempt to save on memory constraints\n",
        "del pandas_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ZPmsAh7o6hC"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "CMoziXTDJWcu"
      },
      "outputs": [],
      "source": [
        "def select_features(from_columns, elements_to_remove):\n",
        "    features = list(filter(lambda x: x not in elements_to_remove, from_columns))\n",
        "    return features\n",
        "\n",
        "def Xy(data, elements_to_remove=[\"domains\", \"actor\"]):\n",
        "    features = select_features(data.columns, elements_to_remove)\n",
        "    X_train = data[features]\n",
        "    y_train = [label2index[actor] for actor in data['actor']]\n",
        "    return X_train, y_train\n",
        "\n",
        "#TRAINING DATA\n",
        "X_train, y_train = Xy(train_data, [\"domains\"])\n",
        "del train_data\n",
        "train_data = tfdf.keras.pd_dataframe_to_tf_dataset(X_train, label=\"actor\")\n",
        "\n",
        "#VALIDATION DATA\n",
        "X_val, y_val = Xy(validation_data, [\"domains\"])\n",
        "del validation_data\n",
        "validation_data = tfdf.keras.pd_dataframe_to_tf_dataset(X_val, label=\"actor\")\n",
        "\n",
        "#TEST DATA\n",
        "X_test, y_test = Xy(test_data, [\"domains\"])\n",
        "del test_data\n",
        "test_data = tfdf.keras.pd_dataframe_to_tf_dataset(X_test, label=\"actor\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zSl2_OnlT07X"
      },
      "outputs": [],
      "source": [
        "#code pulled directly from lecture notes\n",
        "#def tf_data(X, y, batch_size=10000):\n",
        "#  # Create TF Dataset\n",
        "#  tf_dataset = tf.data.Dataset.from_tensor_slices((X, y))\n",
        "#  #tf_dataset = tf_dataset.shuffle(buffer_size=len(X))\n",
        "#  tf_dataset = tf_dataset.batch(batch_size)\n",
        "#  tf_dataset = tf_dataset.prefetch(tf.data.AUTOTUNE)\n",
        "#  return tf_dataset\n",
        "#train_data = tf_data(X_train, y_train)\n",
        "#validation_data = tf_data(X_val, y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "id": "J-WIA-6ItrHo",
        "outputId": "8e4c9859-de57-4752-e793-e4c147d03a16"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": "\n        window._wandbApiKey = new Promise((resolve, reject) => {\n            function loadScript(url) {\n            return new Promise(function(resolve, reject) {\n                let newScript = document.createElement(\"script\");\n                newScript.onerror = reject;\n                newScript.onload = resolve;\n                document.body.appendChild(newScript);\n                newScript.src = url;\n            });\n            }\n            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n            const iframe = document.createElement('iframe')\n            iframe.style.cssText = \"width:0;height:0;border:none\"\n            document.body.appendChild(iframe)\n            const handshake = new Postmate({\n                container: iframe,\n                url: 'https://wandb.ai/authorize'\n            });\n            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n            handshake.then(function(child) {\n                child.on('authorize', data => {\n                    clearTimeout(timeout)\n                    resolve(data)\n                });\n            });\n            })\n        });\n    ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 110,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ugx24KvOvdKX"
      },
      "outputs": [],
      "source": [
        "model_name = \"randomforest_6_param\"\n",
        "max_depth = 16\n",
        "num_trees = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "0bY7vwOANgt0",
        "outputId": "a9777d04-3bfe-4b09-e428-fac5bb45357b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Use /tmp/tmpebkk2aek as temporary training directory\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrob-chavez\u001b[0m (\u001b[33mharvardmlops\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.15.11"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20231003_040319-s5fnnz2s</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/harvardmlops/harvardmlops/runs/s5fnnz2s' target=\"_blank\">randomforest_6_param</a></strong> to <a href='https://wandb.ai/harvardmlops/harvardmlops' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/harvardmlops/harvardmlops' target=\"_blank\">https://wandb.ai/harvardmlops/harvardmlops</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/harvardmlops/harvardmlops/runs/s5fnnz2s' target=\"_blank\">https://wandb.ai/harvardmlops/harvardmlops/runs/s5fnnz2s</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/harvardmlops/harvardmlops/runs/s5fnnz2s?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7bc89989b670>"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = tfdf.keras.RandomForestModel(num_threads=4,\n",
        "                                     max_depth = max_depth,\n",
        "                                     num_trees=num_trees,\n",
        "                                     allow_na_conditions=True,\n",
        "                                     verbose=2,\n",
        "                                     name=model_name)\n",
        "model.compile(metrics=[\"accuracy\"])\n",
        "\n",
        "# Initialize a W&B run\n",
        "wandb.init(\n",
        "    project = 'harvardmlops',\n",
        "    config = {\n",
        "      \"num_trees\": num_trees,\n",
        "      \"max_depth\": max_depth,\n",
        "      \"model_name\": model.name\n",
        "    },\n",
        "    name = model.name\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "8988a860c71c4bdf83f31228518f9e61",
            "b1f861c7a8c1488ebcfbabe990f81e68",
            "8d7a15e7ecc341c391de6ff144f30283",
            "f6ceff6e48124525aa8709d9bae2f660",
            "b32c917c958d4e7cabf3621e6bfdad5a",
            "94006a41e8f14670be916dc86489c179",
            "33200cdef8a14704b934b9abbb1af655",
            "294701d8b2074cb992a7b9d2f9abaa63"
          ]
        },
        "id": "Tct1ku6qbsHI",
        "outputId": "9cc6cf2c-cc04-40c9-8574-bfea6d03cd45"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading training dataset...\n",
            "Training tensor examples:\n",
            "Features: {'length': <tf.Tensor 'data:0' shape=(None,) dtype=int64>, 'entropy': <tf.Tensor 'data_1:0' shape=(None,) dtype=float64>, 'number_of_vowels': <tf.Tensor 'data_2:0' shape=(None,) dtype=int64>, 'number_of_consonants': <tf.Tensor 'data_3:0' shape=(None,) dtype=int64>, 'number_of_numbers': <tf.Tensor 'data_4:0' shape=(None,) dtype=int64>, 'number_of_specials': <tf.Tensor 'data_5:0' shape=(None,) dtype=int64>}\n",
            "Label: Tensor(\"data_6:0\", shape=(None,), dtype=int64)\n",
            "Weights: None\n",
            "Normalized tensor features:\n",
            " {'length': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast:0' shape=(None,) dtype=float32>), 'entropy': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_1:0' shape=(None,) dtype=float32>), 'number_of_vowels': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_2:0' shape=(None,) dtype=float32>), 'number_of_consonants': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_3:0' shape=(None,) dtype=float32>), 'number_of_numbers': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_4:0' shape=(None,) dtype=float32>), 'number_of_specials': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_5:0' shape=(None,) dtype=float32>)}\n",
            "Training dataset read in 0:02:09.045666. Found 27898208 examples.\n",
            "Reading validation dataset...\n",
            "Validation tensor examples:\n",
            "Features: {'length': <tf.Tensor 'data:0' shape=(None,) dtype=int64>, 'entropy': <tf.Tensor 'data_1:0' shape=(None,) dtype=float64>, 'number_of_vowels': <tf.Tensor 'data_2:0' shape=(None,) dtype=int64>, 'number_of_consonants': <tf.Tensor 'data_3:0' shape=(None,) dtype=int64>, 'number_of_numbers': <tf.Tensor 'data_4:0' shape=(None,) dtype=int64>, 'number_of_specials': <tf.Tensor 'data_5:0' shape=(None,) dtype=int64>}\n",
            "Label: Tensor(\"data_6:0\", shape=(None,), dtype=int64)\n",
            "Weights: None\n",
            "Normalized tensor features:\n",
            " {'length': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast:0' shape=(None,) dtype=float32>), 'entropy': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_1:0' shape=(None,) dtype=float32>), 'number_of_vowels': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_2:0' shape=(None,) dtype=float32>), 'number_of_consonants': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_3:0' shape=(None,) dtype=float32>), 'number_of_numbers': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_4:0' shape=(None,) dtype=float32>), 'number_of_specials': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_5:0' shape=(None,) dtype=float32>)}\n",
            "Num validation examples: tf.Tensor(1549900, shape=(), dtype=int32)\n",
            "Validation dataset read in 0:00:27.537935. Found 1549900 examples.\n",
            "Training model...\n",
            "Standard output detected as not visible to the user e.g. running in a notebook. Creating a training log redirection. If training gets stuck, try calling tfdf.keras.set_training_logs_redirection(False).\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[INFO 23-10-03 04:08:06.3315 UTC kernel.cc:773] Start Yggdrasil model training\n",
            "[INFO 23-10-03 04:08:06.3315 UTC kernel.cc:774] Collect training examples\n",
            "[INFO 23-10-03 04:08:06.3316 UTC kernel.cc:787] Dataspec guide:\n",
            "column_guides {\n",
            "  column_name_pattern: \"^__LABEL$\"\n",
            "  type: CATEGORICAL\n",
            "  categorial {\n",
            "    min_vocab_frequency: 0\n",
            "    max_vocab_count: -1\n",
            "  }\n",
            "}\n",
            "default_column_guide {\n",
            "  categorial {\n",
            "    max_vocab_count: 2000\n",
            "  }\n",
            "  discretized_numerical {\n",
            "    maximum_num_bins: 255\n",
            "  }\n",
            "}\n",
            "ignore_columns_without_guides: false\n",
            "detect_numerical_as_discretized_numerical: false\n",
            "\n",
            "[INFO 23-10-03 04:08:06.3322 UTC kernel.cc:393] Number of batches: 27899\n",
            "[INFO 23-10-03 04:08:06.3322 UTC kernel.cc:394] Number of examples: 27898208\n",
            "[INFO 23-10-03 04:08:08.3149 UTC kernel.cc:794] Training dataset:\n",
            "Number of records: 27898208\n",
            "Number of columns: 7\n",
            "\n",
            "Number of columns by type:\n",
            "\tNUMERICAL: 6 (85.7143%)\n",
            "\tCATEGORICAL: 1 (14.2857%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "NUMERICAL: 6 (85.7143%)\n",
            "\t1: \"entropy\" NUMERICAL mean:3.45912 min:0 max:4.83292 sd:0.702172\n",
            "\t2: \"length\" NUMERICAL mean:18.1986 min:0 max:73 sd:6.47699\n",
            "\t3: \"number_of_consonants\" NUMERICAL mean:12.8544 min:0 max:67 sd:5.71789\n",
            "\t4: \"number_of_numbers\" NUMERICAL mean:1.45897 min:0 max:51 sd:4.08733\n",
            "\t5: \"number_of_specials\" NUMERICAL mean:1.14189 min:0 max:16 sd:0.470839\n",
            "\t6: \"number_of_vowels\" NUMERICAL mean:4.26788 min:0 max:30 sd:2.29476\n",
            "\n",
            "CATEGORICAL: 1 (14.2857%)\n",
            "\t0: \"__LABEL\" CATEGORICAL integerized vocab-size:32 no-ood-item\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO 23-10-03 04:08:08.3151 UTC kernel.cc:799] Collect validation dataset\n",
            "[INFO 23-10-03 04:08:08.3152 UTC kernel.cc:393] Number of batches: 1550\n",
            "[INFO 23-10-03 04:08:08.3152 UTC kernel.cc:394] Number of examples: 1549900\n",
            "[INFO 23-10-03 04:08:08.4194 UTC kernel.cc:805] Validation dataset:\n",
            "Number of records: 1549900\n",
            "Number of columns: 7\n",
            "\n",
            "Number of columns by type:\n",
            "\tNUMERICAL: 6 (85.7143%)\n",
            "\tCATEGORICAL: 1 (14.2857%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "NUMERICAL: 6 (85.7143%)\n",
            "\t1: \"entropy\" NUMERICAL mean:3.45899 min:0 max:4.72005 sd:0.702533\n",
            "\t2: \"length\" NUMERICAL mean:18.1998 min:0 max:73 sd:6.47831\n",
            "\t3: \"number_of_consonants\" NUMERICAL mean:12.8551 min:0 max:66 sd:5.72079\n",
            "\t4: \"number_of_numbers\" NUMERICAL mean:1.45935 min:0 max:49 sd:4.08961\n",
            "\t5: \"number_of_specials\" NUMERICAL mean:1.14192 min:0 max:10 sd:0.470906\n",
            "\t6: \"number_of_vowels\" NUMERICAL mean:4.2684 min:0 max:20 sd:2.29562\n",
            "\n",
            "CATEGORICAL: 1 (14.2857%)\n",
            "\t0: \"__LABEL\" CATEGORICAL integerized vocab-size:32 no-ood-item\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO 23-10-03 04:08:08.4195 UTC kernel.cc:810] Configure learner\n",
            "[INFO 23-10-03 04:08:08.4197 UTC kernel.cc:824] Training config:\n",
            "learner: \"RANDOM_FOREST\"\n",
            "features: \"^entropy$\"\n",
            "features: \"^length$\"\n",
            "features: \"^number_of_consonants$\"\n",
            "features: \"^number_of_numbers$\"\n",
            "features: \"^number_of_specials$\"\n",
            "features: \"^number_of_vowels$\"\n",
            "label: \"^__LABEL$\"\n",
            "task: CLASSIFICATION\n",
            "random_seed: 123456\n",
            "metadata {\n",
            "  framework: \"TF Keras\"\n",
            "}\n",
            "pure_serving_model: false\n",
            "[yggdrasil_decision_forests.model.random_forest.proto.random_forest_config] {\n",
            "  num_trees: 10\n",
            "  decision_tree {\n",
            "    max_depth: 16\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    keep_non_leaf_label_distribution: true\n",
            "    num_candidate_attributes: 0\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: true\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "    uplift {\n",
            "      min_examples_in_treatment: 5\n",
            "      split_score: KULLBACK_LEIBLER\n",
            "    }\n",
            "  }\n",
            "  winner_take_all_inference: true\n",
            "  compute_oob_performances: true\n",
            "  compute_oob_variable_importances: false\n",
            "  num_oob_variable_importances_permutations: 1\n",
            "  bootstrap_training_dataset: true\n",
            "  bootstrap_size_ratio: 1\n",
            "  adapt_bootstrap_size_ratio_for_maximum_training_duration: false\n",
            "  sampling_with_replacement: true\n",
            "}\n",
            "\n",
            "[INFO 23-10-03 04:08:08.4203 UTC kernel.cc:827] Deployment config:\n",
            "cache_path: \"/tmp/tmpebkk2aek/working_cache\"\n",
            "num_threads: 4\n",
            "try_resume_training: true\n",
            "\n",
            "[INFO 23-10-03 04:08:08.4206 UTC kernel.cc:889] Train model\n",
            "[INFO 23-10-03 04:08:08.4213 UTC random_forest.cc:416] Training random forest on 27898208 example(s) and 6 feature(s).\n",
            "[INFO 23-10-03 04:12:13.8175 UTC random_forest.cc:802] Training of tree  1/10 (tree index:3) done accuracy:0.660142 logloss:12.2497\n",
            "[INFO 23-10-03 04:12:28.7743 UTC random_forest.cc:802] Training of tree  3/10 (tree index:1) done accuracy:0.661128 logloss:11.973\n",
            "[INFO 23-10-03 04:12:39.6972 UTC random_forest.cc:802] Training of tree  4/10 (tree index:2) done accuracy:0.662003 logloss:11.834\n",
            "[INFO 23-10-03 04:16:10.8894 UTC random_forest.cc:802] Training of tree  5/10 (tree index:4) done accuracy:0.662466 logloss:11.7325\n",
            "[INFO 23-10-03 04:16:27.5966 UTC random_forest.cc:802] Training of tree  7/10 (tree index:6) done accuracy:0.663041 logloss:11.5355\n",
            "[INFO 23-10-03 04:20:06.2373 UTC random_forest.cc:802] Training of tree  9/10 (tree index:8) done accuracy:0.662992 logloss:11.3986\n",
            "[INFO 23-10-03 04:20:16.0497 UTC random_forest.cc:802] Training of tree  10/10 (tree index:9) done accuracy:0.66318 logloss:11.3539\n",
            "[INFO 23-10-03 04:20:16.0576 UTC random_forest.cc:882] Final OOB metrics: accuracy:0.66318 logloss:11.3539\n",
            "[INFO 23-10-03 04:20:17.4923 UTC kernel.cc:926] Export model in log directory: /tmp/tmpebkk2aek with prefix 64288e46a4f34a17\n",
            "[INFO 23-10-03 04:20:17.6958 UTC kernel.cc:944] Save model in resources\n",
            "[INFO 23-10-03 04:20:17.7694 UTC abstract_model.cc:881] Model self evaluation:\n",
            "Number of predictions (without weights): 27613998\n",
            "Number of predictions (with weights): 2.7614e+07\n",
            "Task: CLASSIFICATION\n",
            "Label: __LABEL\n",
            "\n",
            "Accuracy: 0.66318  CI95[W][0.663032 0.663328]\n",
            "LogLoss: : 11.3539\n",
            "ErrorRate: : 0.33682\n",
            "\n",
            "Default Accuracy: : 0.0322815\n",
            "Default LogLoss: : 3.43399\n",
            "Default ErrorRate: : 0.967718\n",
            "\n",
            "Confusion Table:\n",
            "truth\\prediction\n",
            "    0       1       2       3       4       5       6       7       8       9      10      11     12      13     14      15      16      17      18      19      20      21      22      23      24      25      26      27      28      29      30      31\n",
            " 0  0       0       0       0       0       0       0       0       0       0       0       0      0       0      0       0       0       0       0       0       0       0       0       0       0       0       0       0       0       0       0       0\n",
            " 1  0  493884       0       0       0       0       0       0       0  301737       0       1      0       0      1       0       1       0       1   38821       0       0       0       0       0       0   56036       0       0       0       0       0\n",
            " 2  0       0  336649   16022       0   60775   33999       0   65475       0       0     455   1346       0   6866       0    8304    4645       0    6210   20050    6719  126296   58370       0   29353       0   59112       0   49864       0       0\n",
            " 3  0       0   34679  818893       0    1278       0       0     755       0       0       5     97       0      9       0      44     125       0       0       0     331       0    2716       0   31848       0       0       0       0       0       0\n",
            " 4  0       0       0       0  885836     199       0       0       0       0    3730    1020      0       0      0       0       3     152       0       0       0       0       0       0       0       0       0       0      39       0       0       0\n",
            " 5  0       0       9       0       0  170181       4       0       0       0   77388    1679   2489     722     94       0   18820    8332       2   27944      11    6053  353521   25190       0       0       0   33099   24392  128910   12581       0\n",
            " 6  0   37702   23511       0       0   63544  138259       0   67379   23252       0    6618   1592       0  20093       0    8608   10266   38468   19162       3    6969  130447   60499   14342       0   16030   12742       0   80086  111128       0\n",
            " 7  0       0       0       0       0       0       0  890865       0       0       0       0      0       0      0       0       0       0       0       0       0       0       0       0       0       0       0       0       0       0       0       0\n",
            " 8  0       0       3       0       0       0       1       0  879678       0       0       2      1       0      1       0     555   10112       0       0       0       0       0       4       0       0       0       0       0       0       0       0\n",
            " 9  0  493798       0       0       0       0       0       0       0  301062       0       2      0       0      1       0       0       0       1   38918       0       0       0       0       0       0   56878       0       0       0       0       0\n",
            "10  0       0       0       0      35   14574       0       0       0       0  792263    4669      0    1068      0       0     137    1773       0       0       0       0       0       0       0       0       0       0   76031       0       0       0\n",
            "11  0    8877    2566     780    4272   17621    1859       5   11285   10960   36525  247097     28   26632    316       0   70768    9799  137307   86019    1258   14134   30955    4091   24894    8225   68138   18471   16116   10442   21455      65\n",
            "12  0   42939    8274       0       0   72539   17352       0   47487   26904       0   10157  12421       0  13036       0    8579    6394   93280   23288       6    8910  152771   70564     627       0   17854   14582       0   99022  143886       0\n",
            "13  0       0      56       0       0    3156      48       0    2209       0    1356    1954      0  722212     10       0   99665    3977       0   16487       0    4999   14015     628    1202       0       0   10661    4637    2328       0       0\n",
            "14  0   30869   19188       0       0   52396  111570       0   58061   19684       0   10027  10564       0  42678       0    8752   11282  105644   17766       7    6805  111078   51227   15667       0   13875   10504       0   73544  109614       0\n",
            "15  0       0       0       0       0       0       0       0       0       0       0       0      0       0      0  891016       0       0       0       0       0       0       0       0       0       0       0       0       0       0       0       0\n",
            "16  0   10662    1657       0      17   18156    2581       0   18819   11261    2193   18900      9  210384    525       0  278091   20804   18586   72368       2   25488   57206    7090   24315       0   20949   25567    4191   20678   20216       0\n",
            "17  0       0       0       0       0    4322    2953       0   10663       0     641     346      3     115    703       0    6214  688504       0       0       0  115724       0   13027   39532       0       0       0    8211       0       0       0\n",
            "18  0   42604       0       0       0     120       6       0       0   29230       0   50781    135       0    395       0       4       0  406566   15127       1       0    1016       0       0       0   60217    2173       0   16409  265968       0\n",
            "19  0   17808       0       0       0     811       0       0       0   29154       0      15      0       0      0       0    2424       0       0  683244       0       0   19077       0       0       0   81909   39199       0   10965    6102       0\n",
            "20  0       0    7268       0       0      90       0       0       0       0       0       0      4       0      1       0       1       0       0    2894  810241       0       0       0       0     107       0   59242       0   10832       0       0\n",
            "21  0       0       0       0       0       0       0       0       0       0       0       0      0       0      0       0      10  116711       0       0       0  724015       0   50110       0       0       0       0       0       0       0       0\n",
            "22  0       0       4       0       0    4551       3       0       0       0       0     857     16       2      6       0   14523       0       0   21473       0       0  844380       0       0       0       0    5027       0       0       0       0\n",
            "23  0       0       2       0       0       0       2       0  218864       0       0       2      1       0      3       0     212   17780       0       0       0   79967       0  574183       0       0       0       0       0       0       0       0\n",
            "24  0       0       0       0       0       0    6553       1       0       0       0      99      0       0    729       0       1   19169       0       0       0       0       0       0  864139       0       0       0       0       0       0     270\n",
            "25  0   10098   75875   71970       0    5822       0       0       0    6240       0      88    168       0     12       0     620     482       1    4197  109695       0   17456       0       0  533086    1232   32010       0   15824    6476       0\n",
            "26  0    7841       0       0       0       0       0       0       0    5632       0    4409      0       0      0       0       0       0   26319   21760       0       0       0       0       0       0  822062       0       0       0    2554       0\n",
            "27  0       0     869       0       0     583       0       0       0       0       0       0      0       0      0       0    1115       0       0   27338    4228       0   70691       0       0       0       0  670082       0  115878       0       0\n",
            "28  0       0       0       0       0     189       0       0       0       0    9127       2      0    1858      0       0     101    3766       0       0       0       0       0       0       0       0       0       0  875617       0       0       0\n",
            "29  0       0       0       0       0     805       0       0       0       0       0      31     22       0      3       0     225       0       1   51657      15       0   54290       0       0       0       0   94355       0  633032   56695       0\n",
            "30  0  103770       0       0       0       0       1       0       0   60709       0   17353    143       0    324       0       0       0  187654   26684       0       0       0       0       0       0   34750       0       0   67056  391932       0\n",
            "31  0       0       0       0       0       0       0       0       0       0       0      39      0       0      0       0       0       0       0       0       0       0       0       0     153       0       0       0       0       0       0  890894\n",
            "Total: 2.7614e+07\n",
            "\n",
            "One vs other classes:\n",
            "\n",
            "[INFO 23-10-03 04:20:17.9268 UTC kernel.cc:1233] Loading model from path /tmp/tmpebkk2aek/model/ with prefix 64288e46a4f34a17\n",
            "[INFO 23-10-03 04:20:18.3833 UTC decision_forest.cc:660] Model loaded with 10 root(s), 176584 node(s), and 6 input feature(s).\n",
            "[INFO 23-10-03 04:20:18.3834 UTC abstract_model.cc:1343] Engine \"RandomForestGeneric\" built\n",
            "[INFO 23-10-03 04:20:18.3835 UTC kernel.cc:1061] Use fast generic engine\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model trained in 0:12:12.119821\n",
            "Compiling model...\n",
            "Model compiled.\n",
            "Training execution time (mins) 15.02772464354833\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8988a860c71c4bdf83f31228518f9e61",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>0</td></tr><tr><td>val_accuracy</td><td>0.66411</td></tr><tr><td>val_loss</td><td>0.0</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">randomforest_6_param</strong> at: <a href='https://wandb.ai/harvardmlops/harvardmlops/runs/s5fnnz2s' target=\"_blank\">https://wandb.ai/harvardmlops/harvardmlops/runs/s5fnnz2s</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20231003_040319-s5fnnz2s/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Train model\n",
        "import time\n",
        "start_time = time.time()\n",
        "training_results = model.fit(train_data,\n",
        "                             callbacks=[WandbCallback()],\n",
        "                             validation_data=validation_data)\n",
        "execution_time = (time.time() - start_time)/60.0\n",
        "print(\"Training execution time (mins)\",execution_time)\n",
        "\n",
        "# Update W&B\n",
        "wandb.config.update({\"execution_time\": execution_time})\n",
        "# Close the W&B run\n",
        "wandb.run.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqnd9uxqtO2I",
        "outputId": "d8ffa14c-4d7b-46b8-c2dc-ea009230551d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1550/1550 [==============================] - 11s 7ms/step - loss: 0.0000e+00 - accuracy: 0.6633\n",
            "\n",
            "loss: 0.0000\n",
            "accuracy: 0.6633\n"
          ]
        }
      ],
      "source": [
        "evaluation = model.evaluate(test_data, return_dict=True)\n",
        "print()\n",
        "\n",
        "for name, value in evaluation.items():\n",
        "  print(f\"{name}: {value:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hmN6qgh6-2aY",
        "outputId": "57c3756b-931a-4762-ca05-edbacbeb184e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Use /tmp/tmpi_zt3_8_ as temporary training directory\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrob-chavez\u001b[0m (\u001b[33mharvardmlops\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.15.12"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20231005_010713-ltvqnatd</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/harvardmlops/harvardmlops/runs/ltvqnatd' target=\"_blank\">gradient_boosted_trees_6_param</a></strong> to <a href='https://wandb.ai/harvardmlops/harvardmlops' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/harvardmlops/harvardmlops' target=\"_blank\">https://wandb.ai/harvardmlops/harvardmlops</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/harvardmlops/harvardmlops/runs/ltvqnatd' target=\"_blank\">https://wandb.ai/harvardmlops/harvardmlops/runs/ltvqnatd</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The save_model argument by default saves the model in the HDF5 format that cannot save custom objects like subclassed models and custom layers. This behavior will be deprecated in a future release in favor of the SavedModel format. Meanwhile, the HDF5 model is saved as W&B files and the SavedModel as W&B Artifacts.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading training dataset...\n",
            "Training tensor examples:\n",
            "Features: {'length': <tf.Tensor 'data:0' shape=(None,) dtype=int64>, 'entropy': <tf.Tensor 'data_1:0' shape=(None,) dtype=float64>, 'number_of_vowels': <tf.Tensor 'data_2:0' shape=(None,) dtype=int64>, 'number_of_consonants': <tf.Tensor 'data_3:0' shape=(None,) dtype=int64>, 'number_of_numbers': <tf.Tensor 'data_4:0' shape=(None,) dtype=int64>, 'number_of_specials': <tf.Tensor 'data_5:0' shape=(None,) dtype=int64>}\n",
            "Label: Tensor(\"data_6:0\", shape=(None,), dtype=int64)\n",
            "Weights: None\n",
            "Normalized tensor features:\n",
            " {'length': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast:0' shape=(None,) dtype=float32>), 'entropy': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_1:0' shape=(None,) dtype=float32>), 'number_of_vowels': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_2:0' shape=(None,) dtype=float32>), 'number_of_consonants': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_3:0' shape=(None,) dtype=float32>), 'number_of_numbers': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_4:0' shape=(None,) dtype=float32>), 'number_of_specials': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_5:0' shape=(None,) dtype=float32>)}\n",
            "Training dataset read in 0:02:04.085801. Found 27898208 examples.\n",
            "Reading validation dataset...\n",
            "Validation tensor examples:\n",
            "Features: {'length': <tf.Tensor 'data:0' shape=(None,) dtype=int64>, 'entropy': <tf.Tensor 'data_1:0' shape=(None,) dtype=float64>, 'number_of_vowels': <tf.Tensor 'data_2:0' shape=(None,) dtype=int64>, 'number_of_consonants': <tf.Tensor 'data_3:0' shape=(None,) dtype=int64>, 'number_of_numbers': <tf.Tensor 'data_4:0' shape=(None,) dtype=int64>, 'number_of_specials': <tf.Tensor 'data_5:0' shape=(None,) dtype=int64>}\n",
            "Label: Tensor(\"data_6:0\", shape=(None,), dtype=int64)\n",
            "Weights: None\n",
            "Normalized tensor features:\n",
            " {'length': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast:0' shape=(None,) dtype=float32>), 'entropy': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_1:0' shape=(None,) dtype=float32>), 'number_of_vowels': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_2:0' shape=(None,) dtype=float32>), 'number_of_consonants': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_3:0' shape=(None,) dtype=float32>), 'number_of_numbers': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_4:0' shape=(None,) dtype=float32>), 'number_of_specials': SemanticTensor(semantic=<Semantic.NUMERICAL: 1>, tensor=<tf.Tensor 'Cast_5:0' shape=(None,) dtype=float32>)}\n",
            "Num validation examples: tf.Tensor(1549900, shape=(), dtype=int32)\n",
            "Validation dataset read in 0:00:07.596916. Found 1549900 examples.\n",
            "Training model...\n",
            "Standard output detected as not visible to the user e.g. running in a notebook. Creating a training log redirection. If training gets stuck, try calling tfdf.keras.set_training_logs_redirection(False).\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[INFO 23-10-05 01:09:28.0361 UTC kernel.cc:773] Start Yggdrasil model training\n",
            "[INFO 23-10-05 01:09:28.0361 UTC kernel.cc:774] Collect training examples\n",
            "[INFO 23-10-05 01:09:28.0361 UTC kernel.cc:787] Dataspec guide:\n",
            "column_guides {\n",
            "  column_name_pattern: \"^__LABEL$\"\n",
            "  type: CATEGORICAL\n",
            "  categorial {\n",
            "    min_vocab_frequency: 0\n",
            "    max_vocab_count: -1\n",
            "  }\n",
            "}\n",
            "default_column_guide {\n",
            "  categorial {\n",
            "    max_vocab_count: 2000\n",
            "  }\n",
            "  discretized_numerical {\n",
            "    maximum_num_bins: 255\n",
            "  }\n",
            "}\n",
            "ignore_columns_without_guides: false\n",
            "detect_numerical_as_discretized_numerical: false\n",
            "\n",
            "[INFO 23-10-05 01:09:28.0373 UTC kernel.cc:393] Number of batches: 27899\n",
            "[INFO 23-10-05 01:09:28.0373 UTC kernel.cc:394] Number of examples: 27898208\n",
            "[INFO 23-10-05 01:09:29.8123 UTC kernel.cc:794] Training dataset:\n",
            "Number of records: 27898208\n",
            "Number of columns: 7\n",
            "\n",
            "Number of columns by type:\n",
            "\tNUMERICAL: 6 (85.7143%)\n",
            "\tCATEGORICAL: 1 (14.2857%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "NUMERICAL: 6 (85.7143%)\n",
            "\t1: \"entropy\" NUMERICAL mean:3.45912 min:0 max:4.83292 sd:0.702172\n",
            "\t2: \"length\" NUMERICAL mean:18.1986 min:0 max:73 sd:6.47699\n",
            "\t3: \"number_of_consonants\" NUMERICAL mean:12.8544 min:0 max:67 sd:5.71789\n",
            "\t4: \"number_of_numbers\" NUMERICAL mean:1.45897 min:0 max:51 sd:4.08733\n",
            "\t5: \"number_of_specials\" NUMERICAL mean:1.14189 min:0 max:16 sd:0.470839\n",
            "\t6: \"number_of_vowels\" NUMERICAL mean:4.26788 min:0 max:30 sd:2.29476\n",
            "\n",
            "CATEGORICAL: 1 (14.2857%)\n",
            "\t0: \"__LABEL\" CATEGORICAL integerized vocab-size:32 no-ood-item\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO 23-10-05 01:09:29.8125 UTC kernel.cc:799] Collect validation dataset\n",
            "[INFO 23-10-05 01:09:29.8125 UTC kernel.cc:393] Number of batches: 1550\n",
            "[INFO 23-10-05 01:09:29.8125 UTC kernel.cc:394] Number of examples: 1549900\n",
            "[INFO 23-10-05 01:09:29.9060 UTC kernel.cc:805] Validation dataset:\n",
            "Number of records: 1549900\n",
            "Number of columns: 7\n",
            "\n",
            "Number of columns by type:\n",
            "\tNUMERICAL: 6 (85.7143%)\n",
            "\tCATEGORICAL: 1 (14.2857%)\n",
            "\n",
            "Columns:\n",
            "\n",
            "NUMERICAL: 6 (85.7143%)\n",
            "\t1: \"entropy\" NUMERICAL mean:3.45899 min:0 max:4.72005 sd:0.702533\n",
            "\t2: \"length\" NUMERICAL mean:18.1998 min:0 max:73 sd:6.47831\n",
            "\t3: \"number_of_consonants\" NUMERICAL mean:12.8551 min:0 max:66 sd:5.72079\n",
            "\t4: \"number_of_numbers\" NUMERICAL mean:1.45935 min:0 max:49 sd:4.08961\n",
            "\t5: \"number_of_specials\" NUMERICAL mean:1.14192 min:0 max:10 sd:0.470906\n",
            "\t6: \"number_of_vowels\" NUMERICAL mean:4.2684 min:0 max:20 sd:2.29562\n",
            "\n",
            "CATEGORICAL: 1 (14.2857%)\n",
            "\t0: \"__LABEL\" CATEGORICAL integerized vocab-size:32 no-ood-item\n",
            "\n",
            "Terminology:\n",
            "\tnas: Number of non-available (i.e. missing) values.\n",
            "\tood: Out of dictionary.\n",
            "\tmanually-defined: Attribute which type is manually defined by the user i.e. the type was not automatically inferred.\n",
            "\ttokenized: The attribute value is obtained through tokenization.\n",
            "\thas-dict: The attribute is attached to a string dictionary e.g. a categorical attribute stored as a string.\n",
            "\tvocab-size: Number of unique values.\n",
            "\n",
            "[INFO 23-10-05 01:09:29.9060 UTC kernel.cc:810] Configure learner\n",
            "[WARNING 23-10-05 01:09:29.9067 UTC gradient_boosted_trees.cc:1830] \"goss_alpha\" set but \"sampling_method\" not equal to \"GOSS\".\n",
            "[WARNING 23-10-05 01:09:29.9068 UTC gradient_boosted_trees.cc:1841] \"goss_beta\" set but \"sampling_method\" not equal to \"GOSS\".\n",
            "[WARNING 23-10-05 01:09:29.9068 UTC gradient_boosted_trees.cc:1855] \"selective_gradient_boosting_ratio\" set but \"sampling_method\" not equal to \"SELGB\".\n",
            "[INFO 23-10-05 01:09:29.9068 UTC kernel.cc:824] Training config:\n",
            "learner: \"GRADIENT_BOOSTED_TREES\"\n",
            "features: \"^entropy$\"\n",
            "features: \"^length$\"\n",
            "features: \"^number_of_consonants$\"\n",
            "features: \"^number_of_numbers$\"\n",
            "features: \"^number_of_specials$\"\n",
            "features: \"^number_of_vowels$\"\n",
            "label: \"^__LABEL$\"\n",
            "task: CLASSIFICATION\n",
            "random_seed: 123456\n",
            "metadata {\n",
            "  framework: \"TF Keras\"\n",
            "}\n",
            "pure_serving_model: false\n",
            "[yggdrasil_decision_forests.model.gradient_boosted_trees.proto.gradient_boosted_trees_config] {\n",
            "  num_trees: 20\n",
            "  decision_tree {\n",
            "    max_depth: 5\n",
            "    min_examples: 5\n",
            "    in_split_min_examples_check: true\n",
            "    keep_non_leaf_label_distribution: true\n",
            "    num_candidate_attributes: -1\n",
            "    missing_value_policy: GLOBAL_IMPUTATION\n",
            "    allow_na_conditions: true\n",
            "    categorical_set_greedy_forward {\n",
            "      sampling: 0.1\n",
            "      max_num_items: -1\n",
            "      min_item_frequency: 1\n",
            "    }\n",
            "    growing_strategy_local {\n",
            "    }\n",
            "    categorical {\n",
            "      cart {\n",
            "      }\n",
            "    }\n",
            "    axis_aligned_split {\n",
            "    }\n",
            "    internal {\n",
            "      sorting_strategy: PRESORTED\n",
            "    }\n",
            "    uplift {\n",
            "      min_examples_in_treatment: 5\n",
            "      split_score: KULLBACK_LEIBLER\n",
            "    }\n",
            "  }\n",
            "  shrinkage: 0.1\n",
            "  loss: DEFAULT\n",
            "  validation_set_ratio: 0.1\n",
            "  validation_interval_in_trees: 1\n",
            "  early_stopping: VALIDATION_LOSS_INCREASE\n",
            "  early_stopping_num_trees_look_ahead: 30\n",
            "  l2_regularization: 0\n",
            "  lambda_loss: 1\n",
            "  mart {\n",
            "  }\n",
            "  adapt_subsample_for_maximum_training_duration: false\n",
            "  l1_regularization: 0\n",
            "  use_hessian_gain: false\n",
            "  l2_regularization_categorical: 1\n",
            "  stochastic_gradient_boosting {\n",
            "    ratio: 1\n",
            "  }\n",
            "  apply_link_function: true\n",
            "  compute_permutation_variable_importance: false\n",
            "  binary_focal_loss_options {\n",
            "    misprediction_exponent: 2\n",
            "    positive_sample_coefficient: 0.5\n",
            "  }\n",
            "  early_stopping_initial_iteration: 10\n",
            "}\n",
            "\n",
            "[INFO 23-10-05 01:09:29.9073 UTC kernel.cc:827] Deployment config:\n",
            "cache_path: \"/tmp/tmpi_zt3_8_/working_cache\"\n",
            "num_threads: 4\n",
            "try_resume_training: true\n",
            "\n",
            "[INFO 23-10-05 01:09:29.9075 UTC kernel.cc:889] Train model\n",
            "[INFO 23-10-05 01:09:29.9077 UTC gradient_boosted_trees.cc:470] Default loss set to MULTINOMIAL_LOG_LIKELIHOOD\n",
            "[WARNING 23-10-05 01:09:29.9077 UTC gradient_boosted_trees.cc:502] The model configuration specifies 20 trees but computation of the validation loss will only start at iteration 10 with 31 trees per iteration. No validation loss will be computed, early stopping is not used.\n",
            "[INFO 23-10-05 01:09:29.9077 UTC gradient_boosted_trees.cc:1097] Training gradient boosted tree on 27898208 example(s) and 6 feature(s).\n",
            "[INFO 23-10-05 01:09:29.9079 UTC gradient_boosted_trees.cc:1140] 27898208 examples used for training and 1549900 examples used for validation\n",
            "[INFO 23-10-05 01:17:56.6973 UTC gradient_boosted_trees.cc:1554] \tnum-trees:1 train-loss:2.193185 train-accuracy:0.616722 valid-loss:2.192342 valid-accuracy:0.616948\n",
            "[INFO 23-10-05 01:26:34.1619 UTC gradient_boosted_trees.cc:1556] \tnum-trees:2 train-loss:1.963212 train-accuracy:0.621225 valid-loss:1.962314 valid-accuracy:0.621574\n",
            "[INFO 23-10-05 01:35:14.2861 UTC gradient_boosted_trees.cc:1556] \tnum-trees:3 train-loss:1.802657 train-accuracy:0.625636 valid-loss:1.801817 valid-accuracy:0.625907\n"
          ]
        }
      ],
      "source": [
        "model_name = \"gradient_boosted_trees_6_param\"\n",
        "max_depth = 5\n",
        "num_trees = 20\n",
        "model_gbt = tfdf.keras.GradientBoostedTreesModel(num_threads=4,\n",
        "                                                 max_depth = max_depth,\n",
        "                                                 num_trees=num_trees,\n",
        "                                                 allow_na_conditions=True,\n",
        "                                                 verbose=2,\n",
        "                                                 name=model_name)\n",
        "model_gbt.compile(metrics=[\"accuracy\"])\n",
        "\n",
        "# Initialize a W&B run\n",
        "wandb.init(\n",
        "    project = 'harvardmlops',\n",
        "    config = {\n",
        "      \"num_trees\": num_trees,\n",
        "      \"max_depth\": max_depth,\n",
        "      \"model_name\": model_gbt.name\n",
        "    },\n",
        "    name = model_gbt.name\n",
        ")\n",
        "\n",
        "# Train model\n",
        "import time\n",
        "start_time = time.time()\n",
        "training_results = model_gbt.fit(train_data,\n",
        "                                 callbacks=[WandbCallback()],\n",
        "                                 validation_data=validation_data)\n",
        "execution_time = (time.time() - start_time)/60.0\n",
        "print(\"Training execution time (mins)\",execution_time)\n",
        "\n",
        "# Update W&B\n",
        "wandb.config.update({\"execution_time\": execution_time})\n",
        "# Close the W&B run\n",
        "wandb.run.finish()\n",
        "evaluation = model_gbt.evaluate(test_data, return_dict=True)\n",
        "print()\n",
        "\n",
        "for name, value in evaluation.items():\n",
        "  print(f\"{name}: {value:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "h5lzy8oIFW4E"
      },
      "outputs": [],
      "source": [
        "#!pip install transformers\n",
        "#!pip install torch torchvision torchaudio -f https://download.pytorch.org/whl/cu111/torch_stable.html\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fn783U9mRa-m",
        "outputId": "7cd0b13d-31a7-474e-bfbb-879bacc8095b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU is available.\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "import torch\n",
        "import numpy as np\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
        "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(\"GPU is available.\")\n",
        "else:\n",
        "    print(\"GPU is not available.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8bJKxoy5EAR4",
        "outputId": "4d724771-8c2c-4034-9c4d-f542bf2e363a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Read data from in GCP bucket in: 0:00:03.264632\n"
          ]
        }
      ],
      "source": [
        "model_name = \"bert_based_model\"\n",
        "# Set a seed for reproducibility\n",
        "seed = 42\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "#location of GCP bucket/folder\n",
        "files = f\"gs://{bucket_name}/{gold_folder}/*/*/*.gzip\"\n",
        "\n",
        "#read files into a dask dataframe\n",
        "df = read(files)\n",
        "\n",
        "#convert to pandas DF for first transformation\n",
        "pandas_df = df.compute()\n",
        "\n",
        "# Get a random sample of 10% of the records\n",
        "sample_percentage = 0.1  # 10%\n",
        "sampled_df = pandas_df.sample(frac=sample_percentage, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PviY8xC5gj5-"
      },
      "outputs": [],
      "source": [
        "label2index ="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "Llfb5zTB9De2",
        "outputId": "7d4ca80b-faf2-430b-eb21-43d851ea8413"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:2622: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrob-chavez\u001b[0m (\u001b[33mharvardmlops\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.15.12"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20231005_020030-x45ocjk9</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/harvardmlops/harvardmlops/runs/x45ocjk9' target=\"_blank\">bert_based</a></strong> to <a href='https://wandb.ai/harvardmlops/harvardmlops' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/harvardmlops/harvardmlops' target=\"_blank\">https://wandb.ai/harvardmlops/harvardmlops</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/harvardmlops/harvardmlops/runs/x45ocjk9' target=\"_blank\">https://wandb.ai/harvardmlops/harvardmlops/runs/x45ocjk9</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 90.47%\n"
          ]
        }
      ],
      "source": [
        "# Check if a GPU is available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define the BERT model and tokenizer\n",
        "model_name = 'bert-base-uncased'\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize the text and convert labels to integers\n",
        "tokenized_text = [tokenizer.encode(domain, truncation=True, add_special_tokens=True, max_length=20, pad_to_max_length=True) for domain in sampled_df['domains']]\n",
        "labels = sampled_df['actor'].map({'symmi':0, 'legit':1, 'ranbyus_v1':2, 'kraken_v1':3, 'not_dga':4, 'pushdo':5,\n",
        "                                  'ranbyus_v2':6, 'zeus-newgoz':7, 'locky':8, 'corebot':9, 'dyre':10, 'shiotob':11,\n",
        "                                  'proslikefan':12, 'nymaim':13, 'ramdo':14, 'necurs':15, 'tinba':16, 'vawtrak_v1':17,\n",
        "                                  'qadars':18, 'matsnu':19, 'fobber_v2':20, 'alureon':21, 'bedep':22, 'dircrypt':23,\n",
        "                                  'rovnix':24, 'sisron':25, 'cryptolocker':26, 'fobber_v1':27, 'chinad':28,\n",
        "                                  'padcrypt':29, 'simda':30})\n",
        "\n",
        "# Split the data into train, validation, and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(tokenized_text, labels, test_size=0.2, random_state=42)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42)\n",
        "\n",
        "X_train = torch.LongTensor(X_train)\n",
        "y_train = torch.LongTensor(np.array(y_train))\n",
        "X_val = torch.LongTensor(X_val)\n",
        "y_val = torch.LongTensor(np.array(y_val))\n",
        "X_test = torch.LongTensor(X_test)\n",
        "y_test = torch.LongTensor(np.array(y_test))\n",
        "\n",
        "# Create data loaders\n",
        "batch_size = 64\n",
        "lr = 1e-5\n",
        "epochs = 3\n",
        "wandb.init(\n",
        "    project = 'harvardmlops',\n",
        "    config = {\n",
        "      \"batch_size\": batch_size,\n",
        "      \"lr\": lr,\n",
        "      \"epochs\":epochs,\n",
        "      \"model_name\": \"bert_based\"\n",
        "    },\n",
        "    name = \"bert_based\"\n",
        ")\n",
        "train_loader = DataLoader(TensorDataset(X_train, y_train), batch_size=wandb.config.batch_size, shuffle=True)\n",
        "val_loader = DataLoader(TensorDataset(X_val, y_val), batch_size=wandb.config.batch_size, shuffle=False)\n",
        "test_loader = DataLoader(TensorDataset(X_test, y_test), batch_size=wandb.config.batch_size, shuffle=False)\n",
        "\n",
        "# Set up training parameters\n",
        "# Initialize a W&B run\n",
        "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=len(sampled_df['actor'].unique()))\n",
        "model = model.to(device)  # Move the model to the GPU\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=wandb.config.lr)\n",
        "num_epochs = wandb.config.epochs\n",
        "\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    for batch in train_loader:\n",
        "        input_ids, labels = [data.to(device) for data in batch]\n",
        "        optimizer.zero_grad()\n",
        "        output = model(input_ids, labels=labels)\n",
        "        loss = output.loss\n",
        "        wandb.log({'train_batch_loss': loss})\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "# Evaluation\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for batch in test_loader:\n",
        "        input_ids, labels = [data.to(device) for data in batch]\n",
        "        output = model(input_ids)\n",
        "        predictions = torch.argmax(output.logits, dim=1)\n",
        "        correct += (predictions == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "accuracy = correct / total\n",
        "wandb.log({'test_accuracy': accuracy})\n",
        "print(f\"Test Accuracy: {accuracy:.2%}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9gKVwDa92JQ",
        "outputId": "ba2a1541-6ec3-4548-8d45-84df9dc5bb83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "a6kVybXy-j9G"
      },
      "outputs": [],
      "source": [
        "model_save_name = 'bert_dga_classifier.pt'\n",
        "path = f\"/content/gdrive/MyDrive/{model_save_name}\"\n",
        "torch.save(model.state_dict(), path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iFHZ1JuX-_VP"
      },
      "outputs": [],
      "source": [
        "#model.load_state_dict(torch.load(path))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "294701d8b2074cb992a7b9d2f9abaa63": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "33200cdef8a14704b934b9abbb1af655": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8988a860c71c4bdf83f31228518f9e61": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b1f861c7a8c1488ebcfbabe990f81e68",
              "IPY_MODEL_8d7a15e7ecc341c391de6ff144f30283"
            ],
            "layout": "IPY_MODEL_f6ceff6e48124525aa8709d9bae2f660"
          }
        },
        "8d7a15e7ecc341c391de6ff144f30283": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33200cdef8a14704b934b9abbb1af655",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_294701d8b2074cb992a7b9d2f9abaa63",
            "value": 0.05580763753187825
          }
        },
        "94006a41e8f14670be916dc86489c179": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b1f861c7a8c1488ebcfbabe990f81e68": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b32c917c958d4e7cabf3621e6bfdad5a",
            "placeholder": "​",
            "style": "IPY_MODEL_94006a41e8f14670be916dc86489c179",
            "value": "0.002 MB of 0.029 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "b32c917c958d4e7cabf3621e6bfdad5a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6ceff6e48124525aa8709d9bae2f660": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
